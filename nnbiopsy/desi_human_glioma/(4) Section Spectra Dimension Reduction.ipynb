{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "856494bd-971b-4d53-92b6-a772f5934df5",
   "metadata": {},
   "source": [
    "# ***DESI Human Glioma Section Spectra Dimension Reduction***\n",
    "\n",
    "This notebook shows the process of section spectra dimension reduction of the DESI Human Glioma preprocessed dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39df2682-bf3f-4242-94ce-e6bf0b6dcf3c",
   "metadata": {},
   "source": [
    "### ***Import packages***\n",
    "\n",
    "Before we begin, let\"s import all the necessary packages for this notebook.\n",
    "First we add the directory which has our python files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3e2f72dc-fcd1-47d5-8c2d-fea76cfeadc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"../..\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84395cb7-3bb2-46f7-9d9a-794a8eecdab4",
   "metadata": {},
   "source": [
    "Next we import all the necessary packages for this notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "01b61342-ee57-4299-a9ce-a8993f8727fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from typing import Tuple\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras import callbacks\n",
    "from tensorflow.keras import backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage import (filters)\n",
    "from tqdm import tqdm\n",
    "from pyimzml.ImzMLParser import ImzMLParser, getionimage\n",
    "from nnbiopsy.bn_vae import BNVAE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87eebf16-66a7-4b26-8a4b-145d09cbe643",
   "metadata": {},
   "source": [
    "### ***Constants definitions***\n",
    "\n",
    "Next, let\"s define some constant variables for this notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "37a05c91-3223-4591-92cc-1ae0d83e8604",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define folder that contains the dhg dataset and files\n",
    "DHG_PATH = \"C:/Users/Leor/Desktop/Thesis/DHG\"\n",
    "# Define folder that contains the preprocessed dhg dataset\n",
    "DHG_IN_PATH = f\"{DHG_PATH}/Preprocessed\"\n",
    "# Define file that contains dhg clinical state annotations\n",
    "CLINICAL_STATE_ANNOTATIONS_PATH = f\"{DHG_PATH}/Clinical_state_annotations.csv\"\n",
    "# Define folder to save VAE models for later use\n",
    "VAE_MODELS_PATH = \"C:/Users/Leor/Desktop/Thesis/section_vae_models\"\n",
    "# VAE model number of epochs\n",
    "VAE_EPHOCS = 50\n",
    "# VAE model batch size\n",
    "VAE_BATCH_SIZE = 256\n",
    "# VAE model intermidate layer size\n",
    "VAE_INTERMIDATE_LAYER_SIZE = 512\n",
    "# VAE model latent layer size\n",
    "VAE_LATENT_LAYER_SIZE = 10\n",
    "# VAE model learning rate\n",
    "VAE_LEARNING_RATE = 1e-3\n",
    "# MSI Spectra dimension\n",
    "SPECTRA_DIM = 92000\n",
    "# The MSI sample type for filtering\n",
    "SAMPLE_TYPE = \"s\"\n",
    "# Mz value to get in order to threshold for tissue\n",
    "TRESH_MZ = 750\n",
    "# Mz tolerance value to get in order to threshold for tissue\n",
    "TRESH_MZ_TOL = 150\n",
    "# Treshould standard deviation for Gaussian kernel\n",
    "TRESH_GAUSSIAN_SIGMA = 1.5 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c71392-9354-46f8-93d3-d1298fab3820",
   "metadata": {
    "tags": []
   },
   "source": [
    "### ***Reading MSI clinical state anotations***\n",
    "\n",
    "Next, lets read the clinical state anotations for each MSI:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "33f91fd0-b6c6-4965-ad0c-180fbd1c74bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read clinical state annotations csv\n",
    "clinical_state_df = pd.read_csv(CLINICAL_STATE_ANNOTATIONS_PATH)\n",
    "\n",
    "# Filter by sample_type\n",
    "clinical_state_df = clinical_state_df[clinical_state_df[\"sample_type\"] ==\n",
    "                                      SAMPLE_TYPE]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b293bee-e70a-456b-8a75-c703e2ee0f15",
   "metadata": {},
   "source": [
    "### ***Get all tissue spectra from all MSI:***\n",
    "\n",
    "Next, let\"s get all informations except intensities (which need a lot of memory) for each tissue spectra from all MSI:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6aa78851-8993-4315-9e39-0095303a8735",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MSI Loop:   0%|          | 0/24 [00:02<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Leor\\Desktop\\Thesis\\NanoBiopsy\\nnbiopsy\\desi_human_glioma\\(2) Class.ipynb Cell 11'\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Leor/Desktop/Thesis/NanoBiopsy/nnbiopsy/desi_human_glioma/%282%29%20Class.ipynb#ch0000010?line=10'>11</a>\u001b[0m \u001b[39mfor\u001b[39;00m index, msi_row \u001b[39min\u001b[39;00m tqdm(clinical_state_df\u001b[39m.\u001b[39miterrows(),\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Leor/Desktop/Thesis/NanoBiopsy/nnbiopsy/desi_human_glioma/%282%29%20Class.ipynb#ch0000010?line=11'>12</a>\u001b[0m                            total\u001b[39m=\u001b[39mclinical_state_df\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m],\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Leor/Desktop/Thesis/NanoBiopsy/nnbiopsy/desi_human_glioma/%282%29%20Class.ipynb#ch0000010?line=12'>13</a>\u001b[0m                            desc\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mMSI Loop\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Leor/Desktop/Thesis/NanoBiopsy/nnbiopsy/desi_human_glioma/%282%29%20Class.ipynb#ch0000010?line=13'>14</a>\u001b[0m   \u001b[39m# Parse the MSI file\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Leor/Desktop/Thesis/NanoBiopsy/nnbiopsy/desi_human_glioma/%282%29%20Class.ipynb#ch0000010?line=14'>15</a>\u001b[0m   \u001b[39mwith\u001b[39;00m ImzMLParser(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(DHG_IN_PATH,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Leor/Desktop/Thesis/NanoBiopsy/nnbiopsy/desi_human_glioma/%282%29%20Class.ipynb#ch0000010?line=15'>16</a>\u001b[0m                                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mmsi_row\u001b[39m.\u001b[39mfile_name\u001b[39m}\u001b[39;00m\u001b[39m.imzML\u001b[39m\u001b[39m\"\u001b[39m)) \u001b[39mas\u001b[39;00m reader:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Leor/Desktop/Thesis/NanoBiopsy/nnbiopsy/desi_human_glioma/%282%29%20Class.ipynb#ch0000010?line=16'>17</a>\u001b[0m     \u001b[39m# Get local TIC image of msi in mz region [600, 900]\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Leor/Desktop/Thesis/NanoBiopsy/nnbiopsy/desi_human_glioma/%282%29%20Class.ipynb#ch0000010?line=17'>18</a>\u001b[0m     local_tic_img \u001b[39m=\u001b[39m getionimage(reader, TRESH_MZ, tol\u001b[39m=\u001b[39;49mTRESH_MZ_TOL)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Leor/Desktop/Thesis/NanoBiopsy/nnbiopsy/desi_human_glioma/%282%29%20Class.ipynb#ch0000010?line=19'>20</a>\u001b[0m     \u001b[39m# Threshold image to separate tissue spectra from background\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Leor/Desktop/Thesis/NanoBiopsy/nnbiopsy/desi_human_glioma/%282%29%20Class.ipynb#ch0000010?line=20'>21</a>\u001b[0m     smooth \u001b[39m=\u001b[39m filters\u001b[39m.\u001b[39mgaussian(local_tic_img, sigma\u001b[39m=\u001b[39mTRESH_GAUSSIAN_SIGMA)\n",
      "File \u001b[1;32mc:\\Users\\Leor\\anaconda3\\envs\\tf_gpu_jup\\lib\\site-packages\\pyimzml\\ImzMLParser.py:445\u001b[0m, in \u001b[0;36mgetionimage\u001b[1;34m(p, mz_value, tol, z, reduce_func)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Leor/anaconda3/envs/tf_gpu_jup/lib/site-packages/pyimzml/ImzMLParser.py?line=442'>443</a>\u001b[0m     \u001b[39mUserWarning\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mz coordinate = 0 present, if you\u001b[39m\u001b[39m'\u001b[39m\u001b[39mre getting blank images set getionimage(.., .., z=0)\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    <a href='file:///c%3A/Users/Leor/anaconda3/envs/tf_gpu_jup/lib/site-packages/pyimzml/ImzMLParser.py?line=443'>444</a>\u001b[0m \u001b[39mif\u001b[39;00m z_ \u001b[39m==\u001b[39m z:\n\u001b[1;32m--> <a href='file:///c%3A/Users/Leor/anaconda3/envs/tf_gpu_jup/lib/site-packages/pyimzml/ImzMLParser.py?line=444'>445</a>\u001b[0m     mzs, ints \u001b[39m=\u001b[39m \u001b[39mmap\u001b[39m(\u001b[39mlambda\u001b[39;00m x: np\u001b[39m.\u001b[39masarray(x), p\u001b[39m.\u001b[39;49mgetspectrum(i))\n\u001b[0;32m    <a href='file:///c%3A/Users/Leor/anaconda3/envs/tf_gpu_jup/lib/site-packages/pyimzml/ImzMLParser.py?line=445'>446</a>\u001b[0m     min_i, max_i \u001b[39m=\u001b[39m _bisect_spectrum(mzs, mz_value, tol)\n\u001b[0;32m    <a href='file:///c%3A/Users/Leor/anaconda3/envs/tf_gpu_jup/lib/site-packages/pyimzml/ImzMLParser.py?line=446'>447</a>\u001b[0m     im[y \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m, x \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m] \u001b[39m=\u001b[39m reduce_func(ints[min_i:max_i\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\Leor\\anaconda3\\envs\\tf_gpu_jup\\lib\\site-packages\\pyimzml\\ImzMLParser.py:368\u001b[0m, in \u001b[0;36mImzMLParser.getspectrum\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Leor/anaconda3/envs/tf_gpu_jup/lib/site-packages/pyimzml/ImzMLParser.py?line=352'>353</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgetspectrum\u001b[39m(\u001b[39mself\u001b[39m, index):\n\u001b[0;32m    <a href='file:///c%3A/Users/Leor/anaconda3/envs/tf_gpu_jup/lib/site-packages/pyimzml/ImzMLParser.py?line=353'>354</a>\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Leor/anaconda3/envs/tf_gpu_jup/lib/site-packages/pyimzml/ImzMLParser.py?line=354'>355</a>\u001b[0m \u001b[39m    Reads the spectrum at specified index from the .ibd file.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Leor/anaconda3/envs/tf_gpu_jup/lib/site-packages/pyimzml/ImzMLParser.py?line=355'>356</a>\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Leor/anaconda3/envs/tf_gpu_jup/lib/site-packages/pyimzml/ImzMLParser.py?line=365'>366</a>\u001b[0m \u001b[39m        Sequence of intensity values corresponding to mz_array\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Leor/anaconda3/envs/tf_gpu_jup/lib/site-packages/pyimzml/ImzMLParser.py?line=366'>367</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/Leor/anaconda3/envs/tf_gpu_jup/lib/site-packages/pyimzml/ImzMLParser.py?line=367'>368</a>\u001b[0m     mz_bytes, intensity_bytes \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_spectrum_as_string(index)\n\u001b[0;32m    <a href='file:///c%3A/Users/Leor/anaconda3/envs/tf_gpu_jup/lib/site-packages/pyimzml/ImzMLParser.py?line=368'>369</a>\u001b[0m     mz_array \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mfrombuffer(mz_bytes, dtype\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmzPrecision)\n\u001b[0;32m    <a href='file:///c%3A/Users/Leor/anaconda3/envs/tf_gpu_jup/lib/site-packages/pyimzml/ImzMLParser.py?line=369'>370</a>\u001b[0m     intensity_array \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mfrombuffer(intensity_bytes, dtype\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mintensityPrecision)\n",
      "File \u001b[1;32mc:\\Users\\Leor\\anaconda3\\envs\\tf_gpu_jup\\lib\\site-packages\\pyimzml\\ImzMLParser.py:397\u001b[0m, in \u001b[0;36mImzMLParser.get_spectrum_as_string\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Leor/anaconda3/envs/tf_gpu_jup/lib/site-packages/pyimzml/ImzMLParser.py?line=394'>395</a>\u001b[0m lengths[\u001b[39m1\u001b[39m] \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msizeDict[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mintensityPrecision]\n\u001b[0;32m    <a href='file:///c%3A/Users/Leor/anaconda3/envs/tf_gpu_jup/lib/site-packages/pyimzml/ImzMLParser.py?line=395'>396</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mm\u001b[39m.\u001b[39mseek(offsets[\u001b[39m0\u001b[39m])\n\u001b[1;32m--> <a href='file:///c%3A/Users/Leor/anaconda3/envs/tf_gpu_jup/lib/site-packages/pyimzml/ImzMLParser.py?line=396'>397</a>\u001b[0m mz_string \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mm\u001b[39m.\u001b[39;49mread(lengths[\u001b[39m0\u001b[39;49m])\n\u001b[0;32m    <a href='file:///c%3A/Users/Leor/anaconda3/envs/tf_gpu_jup/lib/site-packages/pyimzml/ImzMLParser.py?line=397'>398</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mm\u001b[39m.\u001b[39mseek(offsets[\u001b[39m1\u001b[39m])\n\u001b[0;32m    <a href='file:///c%3A/Users/Leor/anaconda3/envs/tf_gpu_jup/lib/site-packages/pyimzml/ImzMLParser.py?line=398'>399</a>\u001b[0m intensity_string \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mm\u001b[39m.\u001b[39mread(lengths[\u001b[39m1\u001b[39m])\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Create lists to store each spectra's info\n",
    "file_names = []\n",
    "sample_numbers = []\n",
    "histologies = []\n",
    "who_grades = []\n",
    "x_coordinates = []\n",
    "y_coordinates = []\n",
    "idxs = []\n",
    "\n",
    "# Loop over each MSI\n",
    "for index, msi_row in tqdm(clinical_state_df.iterrows(),\n",
    "                           total=clinical_state_df.shape[0],\n",
    "                           desc=\"MSI Loop\"):\n",
    "  # Parse the MSI file\n",
    "  with ImzMLParser(os.path.join(DHG_IN_PATH,\n",
    "                                f\"{msi_row.file_name}.imzML\")) as reader:\n",
    "    # Get local TIC image of msi in mz region [600, 900]\n",
    "    local_tic_img = getionimage(reader, TRESH_MZ, tol=TRESH_MZ_TOL)\n",
    "\n",
    "    # Threshold image to separate tissue spectra from background\n",
    "    smooth = filters.gaussian(local_tic_img, sigma=TRESH_GAUSSIAN_SIGMA)\n",
    "    thresh_mean = filters.threshold_mean(smooth)\n",
    "    thresh_img = local_tic_img > thresh_mean\n",
    "\n",
    "    # Loop over each spectra\n",
    "    for idx, (x, y, z) in tqdm(enumerate(reader.coordinates),\n",
    "                               total=len(reader.coordinates),\n",
    "                               desc=\"Spectra Loop\"):\n",
    "      # Check if spectra is tissue\n",
    "      if thresh_img[y - 1, x - 1]:\n",
    "        # Keep sample file name of spectra\n",
    "        file_names.append(msi_row.file_name)\n",
    "        # Keep sample number of spectra\n",
    "        sample_numbers.append(msi_row.sample_number)\n",
    "        # Keep sample histology of spectra\n",
    "        histologies.append(msi_row.histology)\n",
    "        # Keep sample who grade of spectra\n",
    "        who_grades.append(msi_row.who_grade)\n",
    "        # Keep x coordinate of spectra\n",
    "        x_coordinates.append(x)\n",
    "        # Keep y coordinate of spectra\n",
    "        y_coordinates.append(y)\n",
    "        # Keep  of spectra\n",
    "        idxs.append(idx)\n",
    "\n",
    "# Convert to numpy array\n",
    "file_names = np.array(file_names)\n",
    "sample_numbers = np.array(sample_numbers)\n",
    "histologies = np.array(histologies)\n",
    "who_grades = np.array(who_grades)\n",
    "x_coordinates = np.array(x_coordinates)\n",
    "y_coordinates = np.array(y_coordinates)\n",
    "idxs = np.array(idxs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b5a70b",
   "metadata": {},
   "source": [
    "### ***MSI parsers opening:***\n",
    "\n",
    "Next, let\"s create parser for each MSI in order to read spectra's for the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b50d38-2238-455d-93a5-202c995c9f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening parsers\n",
    "parsers = {\n",
    "    file_name: ImzMLParser(os.path.join(DHG_IN_PATH, f\"{file_name}.imzML\"))\n",
    "    for file_name in clinical_state_df.file_name.unique()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10da83a3-78b5-48c9-a29f-8aa4ae06876a",
   "metadata": {},
   "source": [
    "### ***Dataset generator:***\n",
    "\n",
    "Next, let\"s create a dataset generator for the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d344c443-1d92-4e78-9330-90c25489e35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_index(index: tf.Tensor) -> Tuple[np.ndarray, np.ndarray]:\n",
    "  \"\"\"Function to map index to model input (spectra) and output (spectra).\n",
    "\n",
    "  Args:\n",
    "      index (tf.Tensor): index to map to corresponding values.\n",
    "\n",
    "  Returns:\n",
    "      Tuple[np.ndarray, np.ndarray]: input (spectra) and output (spectra).\n",
    "  \n",
    "  \"\"\"\n",
    "  # Decoding index from the EagerTensor object\n",
    "  index = index.numpy()\n",
    "  # Reading spectra from parser\n",
    "  file_name = file_names[index]\n",
    "  idx = idxs[index]\n",
    "  _, spectra = parsers[file_name].getspectrum(idx)\n",
    "  # Return spectra twice as input and reconstruction\n",
    "  return (spectra, spectra)\n",
    "\n",
    "\n",
    "def _fixup_shape(x: tf.Tensor, y: tf.Tensor):\n",
    "  \"\"\" Function to Fix the implicit inferring of the shapes of the\n",
    "  output Tensors.\n",
    "\n",
    "  Args:\n",
    "      x (tf.Tensor): input (spectra)\n",
    "      y (tf.Tensor): output (spectra)\n",
    "\n",
    "  Returns:\n",
    "      Tuple[np.ndarray, np.ndarray]: input (spectra) and output (spectra) with\n",
    "        correct shape.\n",
    "  \n",
    "  \"\"\"\n",
    "  x.set_shape([SPECTRA_DIM])\n",
    "  y.set_shape([SPECTRA_DIM])\n",
    "  return x, y\n",
    "\n",
    "\n",
    "def create_ds(indexes: np.ndarray, batch_size: int) -> tf.data.Dataset:\n",
    "  \"\"\"Function to create a dataset for model\n",
    "\n",
    "  Args:\n",
    "      indexes (np.ndarray): indexes of thh dataset\n",
    "      batch_size (int): batch size\n",
    "\n",
    "  Returns:\n",
    "      tf.data.Dataset: dataset\n",
    "  \"\"\"\n",
    "  # Create dataset from generator\n",
    "  ds = tf.data.Dataset.from_tensor_slices(indexes)\n",
    "  # Shuffle the data\n",
    "  ds = ds.shuffle(len(indexes))\n",
    "  # Repeats this data\n",
    "  ds = ds.repeat()\n",
    "  # Map index to spectra\n",
    "  ds = ds.map(lambda i: tf.py_function(\n",
    "      func=map_index, inp=[i], Tout=[tf.float32, tf.float32]))\n",
    "  # Fix the implicit inferring of the shapes of the\n",
    "  # output Tensors\n",
    "  ds = ds.map(_fixup_shape)\n",
    "  # Batch the spectra's\n",
    "  ds = ds.batch(batch_size)\n",
    "  # Prefetch batchs to make sure that a batch is ready to\n",
    "  # be served at all time\n",
    "  ds = ds.prefetch(tf.data.AUTOTUNE)\n",
    "  return ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb64e399",
   "metadata": {},
   "source": [
    "### ***Variational auto encoder:***\n",
    "\n",
    "Next, let\"s create a variational auto encoder model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06243a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add different implemantation of VAE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1fe68ee",
   "metadata": {},
   "source": [
    "### ***LOOCV Dimension reduction:***\n",
    "\n",
    "Next, let\"s apply dimension reduction using LOOCV for best evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3a2175-3091-4045-ab39-5fb746b3f484",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "84/84 [==============================] - 25s 292ms/step - loss: 11.1453 - val_loss: 10.9443\n",
      "Epoch 2/50\n",
      "84/84 [==============================] - 24s 284ms/step - loss: 10.8140 - val_loss: 10.7796\n",
      "Epoch 3/50\n",
      "84/84 [==============================] - 25s 300ms/step - loss: 10.7779 - val_loss: 10.7793\n",
      "Epoch 4/50\n",
      "84/84 [==============================] - 24s 289ms/step - loss: 10.7783 - val_loss: 10.7792\n",
      "Epoch 5/50\n",
      "84/84 [==============================] - 23s 281ms/step - loss: 10.7779 - val_loss: 10.7794\n",
      "Epoch 6/50\n",
      "84/84 [==============================] - 22s 270ms/step - loss: 10.7782 - val_loss: 10.7782\n",
      "Epoch 7/50\n",
      "84/84 [==============================] - 21s 251ms/step - loss: 10.7779 - val_loss: 10.7787\n",
      "Epoch 8/50\n",
      "84/84 [==============================] - 22s 266ms/step - loss: 10.7779 - val_loss: 10.7775\n",
      "Epoch 9/50\n",
      "84/84 [==============================] - 21s 247ms/step - loss: 10.7776 - val_loss: 10.7777\n",
      "Epoch 10/50\n",
      "84/84 [==============================] - 23s 278ms/step - loss: 10.7788 - val_loss: 10.7777\n",
      "Epoch 11/50\n",
      "84/84 [==============================] - 22s 270ms/step - loss: nan - val_loss: nan\n",
      "Epoch 12/50\n",
      "84/84 [==============================] - 23s 272ms/step - loss: nan - val_loss: nan\n",
      "Epoch 13/50\n",
      "84/84 [==============================] - 23s 276ms/step - loss: nan - val_loss: nan\n",
      "Epoch 14/50\n",
      "84/84 [==============================] - 22s 269ms/step - loss: nan - val_loss: nan\n",
      "Epoch 15/50\n",
      "84/84 [==============================] - 23s 279ms/step - loss: nan - val_loss: nan\n",
      "Epoch 16/50\n",
      "84/84 [==============================] - 22s 263ms/step - loss: nan - val_loss: nan\n",
      "Epoch 17/50\n",
      "84/84 [==============================] - 22s 259ms/step - loss: nan - val_loss: nan\n",
      "Epoch 18/50\n",
      "84/84 [==============================] - 23s 276ms/step - loss: nan - val_loss: nan\n",
      "Epoch 19/50\n",
      "58/84 [===================>..........] - ETA: 4s - loss: nan"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [07:11<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Leor\\Desktop\\Thesis\\NanoBiopsy\\nnbiopsy\\desi_human_glioma\\(2) Class.ipynb Cell 19'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Leor/Desktop/Thesis/NanoBiopsy/nnbiopsy/desi_human_glioma/%282%29%20Class.ipynb#ch0000014?line=45'>46</a>\u001b[0m vae_model\u001b[39m.\u001b[39mcompile(optimizer, loss\u001b[39m=\u001b[39mlosses\u001b[39m.\u001b[39mCategoricalCrossentropy())\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Leor/Desktop/Thesis/NanoBiopsy/nnbiopsy/desi_human_glioma/%282%29%20Class.ipynb#ch0000014?line=47'>48</a>\u001b[0m \u001b[39m# Train the VAE model\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Leor/Desktop/Thesis/NanoBiopsy/nnbiopsy/desi_human_glioma/%282%29%20Class.ipynb#ch0000014?line=48'>49</a>\u001b[0m history \u001b[39m=\u001b[39m vae_model\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Leor/Desktop/Thesis/NanoBiopsy/nnbiopsy/desi_human_glioma/%282%29%20Class.ipynb#ch0000014?line=49'>50</a>\u001b[0m     x\u001b[39m=\u001b[39;49mtraining_generator,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Leor/Desktop/Thesis/NanoBiopsy/nnbiopsy/desi_human_glioma/%282%29%20Class.ipynb#ch0000014?line=50'>51</a>\u001b[0m     validation_data\u001b[39m=\u001b[39;49mvalidation_generator,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Leor/Desktop/Thesis/NanoBiopsy/nnbiopsy/desi_human_glioma/%282%29%20Class.ipynb#ch0000014?line=51'>52</a>\u001b[0m     epochs\u001b[39m=\u001b[39;49mVAE_EPHOCS,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Leor/Desktop/Thesis/NanoBiopsy/nnbiopsy/desi_human_glioma/%282%29%20Class.ipynb#ch0000014?line=52'>53</a>\u001b[0m     steps_per_epoch\u001b[39m=\u001b[39;49mnp\u001b[39m.\u001b[39;49mceil(\u001b[39mlen\u001b[39;49m(train_indexes) \u001b[39m/\u001b[39;49m VAE_BATCH_SIZE),\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Leor/Desktop/Thesis/NanoBiopsy/nnbiopsy/desi_human_glioma/%282%29%20Class.ipynb#ch0000014?line=53'>54</a>\u001b[0m     validation_steps\u001b[39m=\u001b[39;49mnp\u001b[39m.\u001b[39;49mceil(\u001b[39mlen\u001b[39;49m(val_indexes) \u001b[39m/\u001b[39;49m VAE_BATCH_SIZE),\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Leor/Desktop/Thesis/NanoBiopsy/nnbiopsy/desi_human_glioma/%282%29%20Class.ipynb#ch0000014?line=54'>55</a>\u001b[0m     callbacks\u001b[39m=\u001b[39;49m[model_checkpoint_callback])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Leor/Desktop/Thesis/NanoBiopsy/nnbiopsy/desi_human_glioma/%282%29%20Class.ipynb#ch0000014?line=56'>57</a>\u001b[0m \u001b[39m# Load the saved weights into the model\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Leor/Desktop/Thesis/NanoBiopsy/nnbiopsy/desi_human_glioma/%282%29%20Class.ipynb#ch0000014?line=57'>58</a>\u001b[0m vae_model\u001b[39m.\u001b[39mload_weights(checkpoint_filepath)\n",
      "File \u001b[1;32mc:\\Users\\Leor\\anaconda3\\envs\\tf_gpu_jup\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1193\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/Leor/anaconda3/envs/tf_gpu_jup/lib/site-packages/tensorflow/python/keras/engine/training.py?line=1185'>1186</a>\u001b[0m \u001b[39mwith\u001b[39;00m trace\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   <a href='file:///c%3A/Users/Leor/anaconda3/envs/tf_gpu_jup/lib/site-packages/tensorflow/python/keras/engine/training.py?line=1186'>1187</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   <a href='file:///c%3A/Users/Leor/anaconda3/envs/tf_gpu_jup/lib/site-packages/tensorflow/python/keras/engine/training.py?line=1187'>1188</a>\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   <a href='file:///c%3A/Users/Leor/anaconda3/envs/tf_gpu_jup/lib/site-packages/tensorflow/python/keras/engine/training.py?line=1188'>1189</a>\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[0;32m   <a href='file:///c%3A/Users/Leor/anaconda3/envs/tf_gpu_jup/lib/site-packages/tensorflow/python/keras/engine/training.py?line=1189'>1190</a>\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[0;32m   <a href='file:///c%3A/Users/Leor/anaconda3/envs/tf_gpu_jup/lib/site-packages/tensorflow/python/keras/engine/training.py?line=1190'>1191</a>\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m   <a href='file:///c%3A/Users/Leor/anaconda3/envs/tf_gpu_jup/lib/site-packages/tensorflow/python/keras/engine/training.py?line=1191'>1192</a>\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> <a href='file:///c%3A/Users/Leor/anaconda3/envs/tf_gpu_jup/lib/site-packages/tensorflow/python/keras/engine/training.py?line=1192'>1193</a>\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   <a href='file:///c%3A/Users/Leor/anaconda3/envs/tf_gpu_jup/lib/site-packages/tensorflow/python/keras/engine/training.py?line=1193'>1194</a>\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   <a href='file:///c%3A/Users/Leor/anaconda3/envs/tf_gpu_jup/lib/site-packages/tensorflow/python/keras/engine/training.py?line=1194'>1195</a>\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\Leor\\anaconda3\\envs\\tf_gpu_jup\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:885\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Leor/anaconda3/envs/tf_gpu_jup/lib/site-packages/tensorflow/python/eager/def_function.py?line=881'>882</a>\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Users/Leor/anaconda3/envs/tf_gpu_jup/lib/site-packages/tensorflow/python/eager/def_function.py?line=883'>884</a>\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> <a href='file:///c%3A/Users/Leor/anaconda3/envs/tf_gpu_jup/lib/site-packages/tensorflow/python/eager/def_function.py?line=884'>885</a>\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    <a href='file:///c%3A/Users/Leor/anaconda3/envs/tf_gpu_jup/lib/site-packages/tensorflow/python/eager/def_function.py?line=886'>887</a>\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    <a href='file:///c%3A/Users/Leor/anaconda3/envs/tf_gpu_jup/lib/site-packages/tensorflow/python/eager/def_function.py?line=887'>888</a>\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\Leor\\anaconda3\\envs\\tf_gpu_jup\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:917\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Leor/anaconda3/envs/tf_gpu_jup/lib/site-packages/tensorflow/python/eager/def_function.py?line=913'>914</a>\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    <a href='file:///c%3A/Users/Leor/anaconda3/envs/tf_gpu_jup/lib/site-packages/tensorflow/python/eager/def_function.py?line=914'>915</a>\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Leor/anaconda3/envs/tf_gpu_jup/lib/site-packages/tensorflow/python/eager/def_function.py?line=915'>916</a>\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/Leor/anaconda3/envs/tf_gpu_jup/lib/site-packages/tensorflow/python/eager/def_function.py?line=916'>917</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateless_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Leor/anaconda3/envs/tf_gpu_jup/lib/site-packages/tensorflow/python/eager/def_function.py?line=917'>918</a>\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/Leor/anaconda3/envs/tf_gpu_jup/lib/site-packages/tensorflow/python/eager/def_function.py?line=918'>919</a>\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Leor/anaconda3/envs/tf_gpu_jup/lib/site-packages/tensorflow/python/eager/def_function.py?line=919'>920</a>\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Leor/anaconda3/envs/tf_gpu_jup/lib/site-packages/tensorflow/python/eager/def_function.py?line=920'>921</a>\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\Leor\\anaconda3\\envs\\tf_gpu_jup\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3039\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/Leor/anaconda3/envs/tf_gpu_jup/lib/site-packages/tensorflow/python/eager/function.py?line=3035'>3036</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   <a href='file:///c%3A/Users/Leor/anaconda3/envs/tf_gpu_jup/lib/site-packages/tensorflow/python/eager/function.py?line=3036'>3037</a>\u001b[0m   (graph_function,\n\u001b[0;32m   <a href='file:///c%3A/Users/Leor/anaconda3/envs/tf_gpu_jup/lib/site-packages/tensorflow/python/eager/function.py?line=3037'>3038</a>\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> <a href='file:///c%3A/Users/Leor/anaconda3/envs/tf_gpu_jup/lib/site-packages/tensorflow/python/eager/function.py?line=3038'>3039</a>\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   <a href='file:///c%3A/Users/Leor/anaconda3/envs/tf_gpu_jup/lib/site-packages/tensorflow/python/eager/function.py?line=3039'>3040</a>\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\Users\\Leor\\anaconda3\\envs\\tf_gpu_jup\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1963\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/Leor/anaconda3/envs/tf_gpu_jup/lib/site-packages/tensorflow/python/eager/function.py?line=1958'>1959</a>\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   <a href='file:///c%3A/Users/Leor/anaconda3/envs/tf_gpu_jup/lib/site-packages/tensorflow/python/eager/function.py?line=1959'>1960</a>\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   <a href='file:///c%3A/Users/Leor/anaconda3/envs/tf_gpu_jup/lib/site-packages/tensorflow/python/eager/function.py?line=1960'>1961</a>\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   <a href='file:///c%3A/Users/Leor/anaconda3/envs/tf_gpu_jup/lib/site-packages/tensorflow/python/eager/function.py?line=1961'>1962</a>\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> <a href='file:///c%3A/Users/Leor/anaconda3/envs/tf_gpu_jup/lib/site-packages/tensorflow/python/eager/function.py?line=1962'>1963</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   <a href='file:///c%3A/Users/Leor/anaconda3/envs/tf_gpu_jup/lib/site-packages/tensorflow/python/eager/function.py?line=1963'>1964</a>\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   <a href='file:///c%3A/Users/Leor/anaconda3/envs/tf_gpu_jup/lib/site-packages/tensorflow/python/eager/function.py?line=1964'>1965</a>\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   <a href='file:///c%3A/Users/Leor/anaconda3/envs/tf_gpu_jup/lib/site-packages/tensorflow/python/eager/function.py?line=1965'>1966</a>\u001b[0m     args,\n\u001b[0;32m   <a href='file:///c%3A/Users/Leor/anaconda3/envs/tf_gpu_jup/lib/site-packages/tensorflow/python/eager/function.py?line=1966'>1967</a>\u001b[0m     possible_gradient_type,\n\u001b[0;32m   <a href='file:///c%3A/Users/Leor/anaconda3/envs/tf_gpu_jup/lib/site-packages/tensorflow/python/eager/function.py?line=1967'>1968</a>\u001b[0m     executing_eagerly)\n\u001b[0;32m   <a href='file:///c%3A/Users/Leor/anaconda3/envs/tf_gpu_jup/lib/site-packages/tensorflow/python/eager/function.py?line=1968'>1969</a>\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\Leor\\anaconda3\\envs\\tf_gpu_jup\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:591\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Leor/anaconda3/envs/tf_gpu_jup/lib/site-packages/tensorflow/python/eager/function.py?line=588'>589</a>\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    <a href='file:///c%3A/Users/Leor/anaconda3/envs/tf_gpu_jup/lib/site-packages/tensorflow/python/eager/function.py?line=589'>590</a>\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///c%3A/Users/Leor/anaconda3/envs/tf_gpu_jup/lib/site-packages/tensorflow/python/eager/function.py?line=590'>591</a>\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    <a href='file:///c%3A/Users/Leor/anaconda3/envs/tf_gpu_jup/lib/site-packages/tensorflow/python/eager/function.py?line=591'>592</a>\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    <a href='file:///c%3A/Users/Leor/anaconda3/envs/tf_gpu_jup/lib/site-packages/tensorflow/python/eager/function.py?line=592'>593</a>\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    <a href='file:///c%3A/Users/Leor/anaconda3/envs/tf_gpu_jup/lib/site-packages/tensorflow/python/eager/function.py?line=593'>594</a>\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    <a href='file:///c%3A/Users/Leor/anaconda3/envs/tf_gpu_jup/lib/site-packages/tensorflow/python/eager/function.py?line=594'>595</a>\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    <a href='file:///c%3A/Users/Leor/anaconda3/envs/tf_gpu_jup/lib/site-packages/tensorflow/python/eager/function.py?line=595'>596</a>\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    <a href='file:///c%3A/Users/Leor/anaconda3/envs/tf_gpu_jup/lib/site-packages/tensorflow/python/eager/function.py?line=596'>597</a>\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/Leor/anaconda3/envs/tf_gpu_jup/lib/site-packages/tensorflow/python/eager/function.py?line=597'>598</a>\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    <a href='file:///c%3A/Users/Leor/anaconda3/envs/tf_gpu_jup/lib/site-packages/tensorflow/python/eager/function.py?line=598'>599</a>\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    <a href='file:///c%3A/Users/Leor/anaconda3/envs/tf_gpu_jup/lib/site-packages/tensorflow/python/eager/function.py?line=599'>600</a>\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Leor/anaconda3/envs/tf_gpu_jup/lib/site-packages/tensorflow/python/eager/function.py?line=602'>603</a>\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    <a href='file:///c%3A/Users/Leor/anaconda3/envs/tf_gpu_jup/lib/site-packages/tensorflow/python/eager/function.py?line=603'>604</a>\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\Leor\\anaconda3\\envs\\tf_gpu_jup\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:59\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/Leor/anaconda3/envs/tf_gpu_jup/lib/site-packages/tensorflow/python/eager/execute.py?line=56'>57</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     <a href='file:///c%3A/Users/Leor/anaconda3/envs/tf_gpu_jup/lib/site-packages/tensorflow/python/eager/execute.py?line=57'>58</a>\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> <a href='file:///c%3A/Users/Leor/anaconda3/envs/tf_gpu_jup/lib/site-packages/tensorflow/python/eager/execute.py?line=58'>59</a>\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     <a href='file:///c%3A/Users/Leor/anaconda3/envs/tf_gpu_jup/lib/site-packages/tensorflow/python/eager/execute.py?line=59'>60</a>\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     <a href='file:///c%3A/Users/Leor/anaconda3/envs/tf_gpu_jup/lib/site-packages/tensorflow/python/eager/execute.py?line=60'>61</a>\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     <a href='file:///c%3A/Users/Leor/anaconda3/envs/tf_gpu_jup/lib/site-packages/tensorflow/python/eager/execute.py?line=61'>62</a>\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Loop over each sample number\n",
    "for exclude_sample in tqdm(np.unique(sample_numbers)[:1]):\n",
    "  # Clear graph\n",
    "  K.clear_session()\n",
    "  gc.collect()\n",
    "\n",
    "  # Create filter for training data\n",
    "  train_filter = (sample_numbers != exclude_sample)\n",
    "\n",
    "  # Get indexes of all data\n",
    "  indexes = np.arange(len(sample_numbers))\n",
    "\n",
    "  # Get indexes of training data\n",
    "  train_indexes = indexes[train_filter]\n",
    "\n",
    "  # Get binary labels\n",
    "  labels = who_grades > 2\n",
    "\n",
    "  # Get indexes of training and validation data\n",
    "  train_indexes, val_indexes = train_test_split(train_indexes,\n",
    "                                                test_size=0.2,\n",
    "                                                random_state=0,\n",
    "                                                stratify=labels[train_filter])\n",
    "\n",
    "  # Create data generators\n",
    "  training_generator = create_ds(train_indexes, VAE_BATCH_SIZE)\n",
    "  validation_generator = create_ds(val_indexes, VAE_BATCH_SIZE)\n",
    "  test_generator = create_ds(indexes[~train_filter], VAE_BATCH_SIZE)\n",
    "\n",
    "  # Create Callback to save the best model\n",
    "  checkpoint_filepath = os.path.join(VAE_MODELS_PATH,\n",
    "                                     f\"excluded_{exclude_sample}/\")\n",
    "  model_checkpoint_callback = callbacks.ModelCheckpoint(\n",
    "      filepath=checkpoint_filepath,\n",
    "      save_weights_only=True,\n",
    "      monitor=\"val_loss\",\n",
    "      mode=\"min\",\n",
    "      save_best_only=True)\n",
    "\n",
    "  # Create VAE model\n",
    "  vae_model = BNVAE(SPECTRA_DIM, VAE_INTERMIDATE_LAYER_SIZE,\n",
    "                    VAE_LATENT_LAYER_SIZE)\n",
    "\n",
    "  # Compile the VAE model\n",
    "  optimizer = optimizers.Adam(learning_rate=VAE_LEARNING_RATE)\n",
    "  vae_model.compile(optimizer, loss=losses.CategoricalCrossentropy())\n",
    "\n",
    "  # Train the VAE model\n",
    "  history = vae_model.fit(\n",
    "      x=training_generator,\n",
    "      validation_data=validation_generator,\n",
    "      epochs=VAE_EPHOCS,\n",
    "      steps_per_epoch=np.ceil(len(train_indexes) / VAE_BATCH_SIZE),\n",
    "      validation_steps=np.ceil(len(val_indexes) / VAE_BATCH_SIZE),\n",
    "      callbacks=[model_checkpoint_callback])\n",
    "\n",
    "  # Load the saved weights into the model\n",
    "  vae_model.load_weights(checkpoint_filepath)\n",
    "\n",
    "  # Evalute The NN on test set\n",
    "  test_eval = vae_model.evaluate(x=test_generator,\n",
    "                                 steps=np.ceil(\n",
    "                                     len(val_indexes) / VAE_BATCH_SIZE))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7b822b",
   "metadata": {},
   "source": [
    "### ***MSI parsers closing:***\n",
    "\n",
    "Next, let\"s close MSI parsers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5bdfc8-4b31-4968-ae11-f271467cbec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Closing parsers\n",
    "for reader in parsers.values():\n",
    "  if reader.m:\n",
    "    reader.m.close()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5c73559c04fc51cf6f25e380b3ded5183311c605494f1c18f4c2cfbf285cb958"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('tf_gpu_jup')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
