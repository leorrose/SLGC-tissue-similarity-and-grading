{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "856494bd-971b-4d53-92b6-a772f5934df5",
   "metadata": {},
   "source": [
    "# ***DESI Human Glioma Section Spectra Clinical State Classification***\n",
    "\n",
    "This notebook shows the process of section spectra clinical state classification of the DESI Human Glioma preprocessed dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39df2682-bf3f-4242-94ce-e6bf0b6dcf3c",
   "metadata": {},
   "source": [
    "### ***Import packages***\n",
    "\n",
    "Before we begin, let\"s import all the necessary packages for this notebook.\n",
    "First we add the directory which has our python files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e2f72dc-fcd1-47d5-8c2d-fea76cfeadc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"../..\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84395cb7-3bb2-46f7-9d9a-794a8eecdab4",
   "metadata": {},
   "source": [
    "Next we import all the necessary packages for this notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01b61342-ee57-4299-a9ce-a8993f8727fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from typing import Tuple\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras import callbacks\n",
    "from tensorflow.keras import backend as K\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage import (filters)\n",
    "from tqdm import tqdm\n",
    "from pyimzml.ImzMLParser import ImzMLParser, getionimage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87eebf16-66a7-4b26-8a4b-145d09cbe643",
   "metadata": {},
   "source": [
    "### ***Constants definitions***\n",
    "\n",
    "Next, let\"s define some constant variables for this notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37a05c91-3223-4591-92cc-1ae0d83e8604",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define folder that contains the dhg dataset and files\n",
    "DHG_PATH = \"C:/Users/Leor/Desktop/Thesis/DHG\"\n",
    "# Define folder that contains the preprocessed dhg dataset\n",
    "DHG_IN_PATH = f\"{DHG_PATH}/Preprocessed\"\n",
    "# Define file that contains dhg clinical state annotations\n",
    "CLINICAL_STATE_ANNOTATIONS_PATH = f\"{DHG_PATH}/Clinical_state_annotations.csv\"\n",
    "# Define folder to save classification models for later use\n",
    "MODELS_PATH = \"C:/Users/Leor/Desktop/Thesis/section_classification_models\"\n",
    "# Classification model number of epochs\n",
    "EPHOCS = 50\n",
    "# Classification model batch size\n",
    "BATCH_SIZE = 256\n",
    "# Classification model learning rate\n",
    "LEARNING_RATE = 1e-3\n",
    "# MSI Spectra dimension\n",
    "SPECTRA_DIM = 92000\n",
    "# The MSI sample type for filtering\n",
    "SAMPLE_TYPE = \"s\"\n",
    "# Mz value to get in order to threshold for tissue\n",
    "TRESH_MZ = 750\n",
    "# Mz tolerance value to get in order to threshold for tissue\n",
    "TRESH_MZ_TOL = 150\n",
    "# Treshould standard deviation for Gaussian kernel\n",
    "TRESH_GAUSSIAN_SIGMA = 1.5 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c71392-9354-46f8-93d3-d1298fab3820",
   "metadata": {
    "tags": []
   },
   "source": [
    "### ***Reading MSI clinical state anotations***\n",
    "\n",
    "Next, lets read the clinical state anotations for each MSI:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33f91fd0-b6c6-4965-ad0c-180fbd1c74bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read clinical state annotations csv\n",
    "clinical_state_df = pd.read_csv(CLINICAL_STATE_ANNOTATIONS_PATH)\n",
    "\n",
    "# Filter by sample_type\n",
    "clinical_state_df = clinical_state_df[clinical_state_df[\"sample_type\"] ==\n",
    "                                      SAMPLE_TYPE]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b293bee-e70a-456b-8a75-c703e2ee0f15",
   "metadata": {},
   "source": [
    "### ***Get all tissue spectra from all MSI:***\n",
    "\n",
    "Next, let\"s get all informations except intensities (which need a lot of memory) for each tissue spectra from all MSI:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6aa78851-8993-4315-9e39-0095303a8735",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Spectra Loop: 100%|██████████| 2304/2304 [00:00<00:00, 135657.20it/s]\n",
      "Spectra Loop: 100%|██████████| 2254/2254 [00:00<00:00, 172975.23it/s]\n",
      "Spectra Loop: 100%|██████████| 2596/2596 [00:00<00:00, 153125.01it/s]\n",
      "Spectra Loop: 100%|██████████| 2772/2772 [00:00<00:00, 110400.53it/s]\n",
      "Spectra Loop: 100%|██████████| 2898/2898 [00:00<00:00, 110925.39it/s]\n",
      "Spectra Loop: 100%|██████████| 2508/2508 [00:00<00:00, 114244.76it/s]\n",
      "Spectra Loop: 100%|██████████| 3871/3871 [00:00<00:00, 104902.99it/s]\n",
      "Spectra Loop: 100%|██████████| 2928/2928 [00:00<00:00, 117435.38it/s]\n",
      "Spectra Loop: 100%|██████████| 3604/3604 [00:00<00:00, 144549.57it/s]\n",
      "Spectra Loop: 100%|██████████| 1584/1584 [00:00<00:00, 79408.33it/s]\n",
      "Spectra Loop: 100%|██████████| 1620/1620 [00:00<00:00, 124947.55it/s]\n",
      "Spectra Loop: 100%|██████████| 1377/1377 [00:00<00:00, 98580.86it/s]\n",
      "Spectra Loop: 100%|██████████| 3484/3484 [00:00<00:00, 143533.04it/s]\n",
      "Spectra Loop: 100%|██████████| 2916/2916 [00:00<00:00, 94235.87it/s]\n",
      "Spectra Loop: 100%|██████████| 2852/2852 [00:00<00:00, 95317.50it/s]\n",
      "Spectra Loop: 100%|██████████| 2583/2583 [00:00<00:00, 112604.32it/s]\n",
      "Spectra Loop: 100%|██████████| 4400/4400 [00:00<00:00, 114745.96it/s]\n",
      "Spectra Loop: 100%|██████████| 2184/2184 [00:00<00:00, 134188.24it/s]\n",
      "Spectra Loop: 100%|██████████| 1850/1850 [00:00<00:00, 122801.56it/s]\n",
      "Spectra Loop: 100%|██████████| 1710/1710 [00:00<00:00, 187314.18it/s]\n",
      "Spectra Loop: 100%|██████████| 1395/1395 [00:00<00:00, 138068.20it/s]\n",
      "Spectra Loop: 100%|██████████| 1470/1470 [00:00<00:00, 145336.89it/s]\n",
      "Spectra Loop: 100%|██████████| 4896/4896 [00:00<00:00, 131476.49it/s]\n",
      "Spectra Loop: 100%|██████████| 1886/1886 [00:00<00:00, 169755.95it/s]\n",
      "MSI Loop: 100%|██████████| 24/24 [02:03<00:00,  5.15s/it]\n"
     ]
    }
   ],
   "source": [
    "# Create lists to store each spectra's info\n",
    "file_names = []\n",
    "sample_numbers = []\n",
    "histologies = []\n",
    "who_grades = []\n",
    "x_coordinates = []\n",
    "y_coordinates = []\n",
    "idxs = []\n",
    "\n",
    "# Loop over each MSI\n",
    "for index, msi_row in tqdm(clinical_state_df.iterrows(),\n",
    "                           total=clinical_state_df.shape[0],\n",
    "                           desc=\"MSI Loop\"):\n",
    "  # Parse the MSI file\n",
    "  with ImzMLParser(os.path.join(DHG_IN_PATH,\n",
    "                                f\"{msi_row.file_name}.imzML\")) as reader:\n",
    "    # Get local TIC image of msi in mz region [600, 900]\n",
    "    local_tic_img = getionimage(reader, TRESH_MZ, tol=TRESH_MZ_TOL)\n",
    "\n",
    "    # Threshold image to separate tissue spectra from background\n",
    "    smooth = filters.gaussian(local_tic_img, sigma=TRESH_GAUSSIAN_SIGMA)\n",
    "    thresh_mean = filters.threshold_mean(smooth)\n",
    "    thresh_img = local_tic_img > thresh_mean\n",
    "\n",
    "    # Loop over each spectra\n",
    "    for idx, (x, y, z) in tqdm(enumerate(reader.coordinates),\n",
    "                               total=len(reader.coordinates),\n",
    "                               desc=\"Spectra Loop\"):\n",
    "      # Check if spectra is tissue\n",
    "      if thresh_img[y - 1, x - 1]:\n",
    "        # Keep sample file name of spectra\n",
    "        file_names.append(msi_row.file_name)\n",
    "        # Keep sample number of spectra\n",
    "        sample_numbers.append(msi_row.sample_number)\n",
    "        # Keep sample histology of spectra\n",
    "        histologies.append(msi_row.histology)\n",
    "        # Keep sample who grade of spectra\n",
    "        who_grades.append(msi_row.who_grade)\n",
    "        # Keep x coordinate of spectra\n",
    "        x_coordinates.append(x)\n",
    "        # Keep y coordinate of spectra\n",
    "        y_coordinates.append(y)\n",
    "        # Keep  of spectra\n",
    "        idxs.append(idx)\n",
    "\n",
    "# Convert to numpy array\n",
    "file_names = np.array(file_names)\n",
    "sample_numbers = np.array(sample_numbers)\n",
    "histologies = np.array(histologies)\n",
    "who_grades = np.array(who_grades)\n",
    "x_coordinates = np.array(x_coordinates)\n",
    "y_coordinates = np.array(y_coordinates)\n",
    "idxs = np.array(idxs)\n",
    "labels = (who_grades > 2).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b5a70b",
   "metadata": {},
   "source": [
    "### ***MSI parsers opening:***\n",
    "\n",
    "Next, let\"s create parser for each MSI in order to read spectra's for the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5b50d38-2238-455d-93a5-202c995c9f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening parsers\n",
    "parsers = {\n",
    "    file_name: ImzMLParser(os.path.join(DHG_IN_PATH, f\"{file_name}.imzML\"))\n",
    "    for file_name in clinical_state_df.file_name.unique()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10da83a3-78b5-48c9-a29f-8aa4ae06876a",
   "metadata": {},
   "source": [
    "### ***Dataset generator:***\n",
    "\n",
    "Next, let\"s create a dataset generator for the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d344c443-1d92-4e78-9330-90c25489e35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_index(index: tf.Tensor) -> Tuple[np.ndarray, int]:\n",
    "  \"\"\"Function to map index to model input (spectra) and output (label).\n",
    "\n",
    "  Args:\n",
    "      index (tf.Tensor): index to map to corresponding values.\n",
    "\n",
    "  Returns:\n",
    "      Tuple[np.ndarray, int]: input (spectra) and output (label).\n",
    "  \n",
    "  \"\"\"\n",
    "  # Decoding index from the EagerTensor object\n",
    "  index = index.numpy()\n",
    "  # Reading spectra from parser\n",
    "  file_name = file_names[index]\n",
    "  idx = idxs[index]\n",
    "  _, spectra = parsers[file_name].getspectrum(idx)\n",
    "  # Return spectra and label\n",
    "  return (spectra, labels[index])\n",
    "\n",
    "\n",
    "def _fixup_shape(x: tf.Tensor, y: tf.Tensor):\n",
    "  \"\"\" Function to Fix the implicit inferring of the shapes of the\n",
    "  output Tensors.\n",
    "\n",
    "  Args:\n",
    "      x (tf.Tensor): input (spectra)\n",
    "      y (tf.Tensor): output (label)\n",
    "\n",
    "  Returns:\n",
    "      Tuple[np.ndarray, np.ndarray]: input (spectra) and output (label) with\n",
    "        correct shape.\n",
    "  \n",
    "  \"\"\"\n",
    "  x.set_shape([SPECTRA_DIM])\n",
    "  y.set_shape([])\n",
    "  return x, y\n",
    "\n",
    "\n",
    "def create_ds(indexes: np.ndarray, batch_size: int) -> tf.data.Dataset:\n",
    "  \"\"\"Function to create a dataset for model\n",
    "\n",
    "  Args:\n",
    "      indexes (np.ndarray): indexes of thh dataset\n",
    "      batch_size (int): batch size\n",
    "\n",
    "  Returns:\n",
    "      tf.data.Dataset: dataset\n",
    "  \"\"\"\n",
    "  # Create dataset from indexes\n",
    "  ds = tf.data.Dataset.from_tensor_slices(indexes)\n",
    "  # Shuffle the data\n",
    "  ds = ds.shuffle(len(indexes))\n",
    "  # Map index to spectra\n",
    "  ds = ds.map(lambda i: tf.py_function(\n",
    "      func=map_index, inp=[i], Tout=[tf.float32, tf.float32]))\n",
    "  # Fix the implicit inferring of the shapes of the\n",
    "  # output Tensors\n",
    "  ds = ds.map(_fixup_shape)\n",
    "  # Batch the spectra's\n",
    "  ds = ds.batch(batch_size)\n",
    "  # Prefetch batchs to make sure that a batch is ready to\n",
    "  # be served at all time\n",
    "  ds = ds.prefetch(tf.data.AUTOTUNE)\n",
    "  return ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb64e399",
   "metadata": {},
   "source": [
    "### ***Classification model:***\n",
    "\n",
    "Next, let\"s create a classification dense neural network model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a06243a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model() -> tf.keras.Model:\n",
    "  \"\"\"Function to generate classification model.\n",
    "\n",
    "  Returns:\n",
    "      tf.keras.Model: classification model.\n",
    "  \n",
    "  \"\"\"\n",
    "  return tf.keras.Sequential(\n",
    "    [\n",
    "      layers.InputLayer(input_shape=(SPECTRA_DIM,)),\n",
    "      layers.Dense(512, activation='relu'),\n",
    "      layers.Dense(512, activation='relu'),\n",
    "      layers.Dense(256, activation='relu'),\n",
    "      layers.Dense(256, activation='relu'),\n",
    "      layers.Dense(128, activation='relu'),\n",
    "      layers.Dense(1, activation='sigmoid')\n",
    "    ]\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1fe68ee",
   "metadata": {},
   "source": [
    "### ***LOOCV Classification:***\n",
    "\n",
    "Next, let\"s apply classification using LOOCV for best evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c3a2175-3091-4045-ab39-5fb746b3f484",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/22 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "84/84 [==============================] - 19s 212ms/step - loss: 0.4842 - accuracy: 0.7522 - val_loss: 0.1255 - val_accuracy: 0.9755\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/section_classification_models\\excluded_2\\assets\n",
      "Epoch 2/50\n",
      "84/84 [==============================] - 20s 241ms/step - loss: 0.0345 - accuracy: 0.9907 - val_loss: 0.0153 - val_accuracy: 0.9942\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/section_classification_models\\excluded_2\\assets\n",
      "Epoch 3/50\n",
      "84/84 [==============================] - 19s 219ms/step - loss: 0.0984 - accuracy: 0.9712 - val_loss: 0.0780 - val_accuracy: 0.9766\n",
      "Epoch 4/50\n",
      "84/84 [==============================] - 18s 211ms/step - loss: 0.0350 - accuracy: 0.9893 - val_loss: 0.0110 - val_accuracy: 0.9964\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/section_classification_models\\excluded_2\\assets\n",
      "Epoch 5/50\n",
      "84/84 [==============================] - 18s 218ms/step - loss: 0.0028 - accuracy: 0.9995 - val_loss: 0.0109 - val_accuracy: 0.9963\n",
      "Epoch 6/50\n",
      "84/84 [==============================] - 19s 222ms/step - loss: 0.0017 - accuracy: 0.9996 - val_loss: 0.0085 - val_accuracy: 0.9972\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/section_classification_models\\excluded_2\\assets\n",
      "Epoch 7/50\n",
      "84/84 [==============================] - 20s 237ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.0081 - val_accuracy: 0.9974\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/section_classification_models\\excluded_2\\assets\n",
      "Epoch 8/50\n",
      "84/84 [==============================] - 18s 218ms/step - loss: 8.8771e-04 - accuracy: 0.9999 - val_loss: 0.0089 - val_accuracy: 0.9970\n",
      "Epoch 9/50\n",
      "84/84 [==============================] - 18s 217ms/step - loss: 7.9256e-04 - accuracy: 0.9999 - val_loss: 0.0117 - val_accuracy: 0.9966\n",
      "Epoch 10/50\n",
      "84/84 [==============================] - 19s 223ms/step - loss: 7.8684e-04 - accuracy: 0.9999 - val_loss: 0.0093 - val_accuracy: 0.9964\n",
      "Epoch 11/50\n",
      "84/84 [==============================] - 20s 232ms/step - loss: 4.5630e-04 - accuracy: 1.0000 - val_loss: 0.0075 - val_accuracy: 0.9978\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/section_classification_models\\excluded_2\\assets\n",
      "Epoch 12/50\n",
      "84/84 [==============================] - 18s 216ms/step - loss: 4.1248e-04 - accuracy: 0.9999 - val_loss: 0.0072 - val_accuracy: 0.9978\n",
      "Epoch 13/50\n",
      "84/84 [==============================] - 18s 215ms/step - loss: 1.7992e-04 - accuracy: 1.0000 - val_loss: 0.0077 - val_accuracy: 0.9978\n",
      "Epoch 14/50\n",
      "84/84 [==============================] - 19s 226ms/step - loss: 5.5099e-05 - accuracy: 1.0000 - val_loss: 0.0071 - val_accuracy: 0.9979\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/section_classification_models\\excluded_2\\assets\n",
      "Epoch 15/50\n",
      "84/84 [==============================] - 20s 236ms/step - loss: 4.0930e-05 - accuracy: 1.0000 - val_loss: 0.0078 - val_accuracy: 0.9978\n",
      "Epoch 16/50\n",
      "84/84 [==============================] - 20s 238ms/step - loss: 3.5378e-05 - accuracy: 1.0000 - val_loss: 0.0073 - val_accuracy: 0.9979\n",
      "Epoch 17/50\n",
      "84/84 [==============================] - 19s 224ms/step - loss: 3.0076e-05 - accuracy: 1.0000 - val_loss: 0.0074 - val_accuracy: 0.9978\n",
      "Epoch 18/50\n",
      "84/84 [==============================] - 20s 242ms/step - loss: 2.5436e-05 - accuracy: 1.0000 - val_loss: 0.0076 - val_accuracy: 0.9978\n",
      "Epoch 19/50\n",
      "84/84 [==============================] - 20s 240ms/step - loss: 2.2189e-05 - accuracy: 1.0000 - val_loss: 0.0077 - val_accuracy: 0.9978\n",
      "Epoch 00019: early stopping\n",
      "3/3 [==============================] - 1s 166ms/step - loss: 15.1979 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 1/22 [06:18<2:12:32, 378.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "83/83 [==============================] - 19s 221ms/step - loss: 0.5115 - accuracy: 0.7249 - val_loss: 0.2134 - val_accuracy: 0.9217\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/section_classification_models\\excluded_3\\assets\n",
      "Epoch 2/50\n",
      "83/83 [==============================] - 18s 219ms/step - loss: 0.0999 - accuracy: 0.9652 - val_loss: 0.0186 - val_accuracy: 0.9938\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/section_classification_models\\excluded_3\\assets\n",
      "Epoch 3/50\n",
      "83/83 [==============================] - 19s 227ms/step - loss: 0.0082 - accuracy: 0.9974 - val_loss: 0.0058 - val_accuracy: 0.9979\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/section_classification_models\\excluded_3\\assets\n",
      "Epoch 4/50\n",
      "83/83 [==============================] - 19s 225ms/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 0.0367 - val_accuracy: 0.9875\n",
      "Epoch 5/50\n",
      "83/83 [==============================] - 18s 219ms/step - loss: 9.2077e-04 - accuracy: 0.9998 - val_loss: 0.0032 - val_accuracy: 0.9987\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/section_classification_models\\excluded_3\\assets\n",
      "Epoch 6/50\n",
      "83/83 [==============================] - 19s 231ms/step - loss: 6.4403e-05 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 0.9989\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/section_classification_models\\excluded_3\\assets\n",
      "Epoch 7/50\n",
      "83/83 [==============================] - 19s 220ms/step - loss: 1.9955e-05 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 0.9989\n",
      "Epoch 8/50\n",
      "83/83 [==============================] - 19s 233ms/step - loss: 8.2812e-06 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 0.9985\n",
      "Epoch 9/50\n",
      "83/83 [==============================] - 19s 228ms/step - loss: 4.9406e-06 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 0.9987\n",
      "Epoch 10/50\n",
      "83/83 [==============================] - 20s 236ms/step - loss: 3.3601e-06 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 0.9987\n",
      "Epoch 11/50\n",
      "83/83 [==============================] - 19s 223ms/step - loss: 2.4903e-06 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 0.9987\n",
      "Epoch 00011: early stopping\n",
      "4/4 [==============================] - 1s 208ms/step - loss: 0.0408 - accuracy: 0.9863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 2/22 [09:57<1:34:55, 284.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "83/83 [==============================] - 19s 229ms/step - loss: 0.4757 - accuracy: 0.7532 - val_loss: 0.2159 - val_accuracy: 0.9199\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/section_classification_models\\excluded_4\\assets\n",
      "Epoch 2/50\n",
      "83/83 [==============================] - 18s 221ms/step - loss: 0.1164 - accuracy: 0.9602 - val_loss: 0.0498 - val_accuracy: 0.9864\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/section_classification_models\\excluded_4\\assets\n",
      "Epoch 3/50\n",
      "83/83 [==============================] - 19s 225ms/step - loss: 0.0193 - accuracy: 0.9934 - val_loss: 0.3730 - val_accuracy: 0.8743\n",
      "Epoch 4/50\n",
      "83/83 [==============================] - 19s 228ms/step - loss: 0.0195 - accuracy: 0.9929 - val_loss: 0.0098 - val_accuracy: 0.9960\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/section_classification_models\\excluded_4\\assets\n",
      "Epoch 5/50\n",
      "83/83 [==============================] - 19s 230ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 0.0058 - val_accuracy: 0.9985\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/section_classification_models\\excluded_4\\assets\n",
      "Epoch 6/50\n",
      "83/83 [==============================] - 19s 228ms/step - loss: 7.8270e-04 - accuracy: 0.9998 - val_loss: 0.0051 - val_accuracy: 0.9977\n",
      "Epoch 7/50\n",
      "83/83 [==============================] - 21s 249ms/step - loss: 8.0024e-05 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 0.9979\n",
      "Epoch 8/50\n",
      "83/83 [==============================] - 21s 251ms/step - loss: 3.3925e-05 - accuracy: 1.0000 - val_loss: 0.0052 - val_accuracy: 0.9979\n",
      "Epoch 9/50\n",
      "83/83 [==============================] - 18s 216ms/step - loss: 1.9171e-05 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 0.9979\n",
      "Epoch 10/50\n",
      "83/83 [==============================] - 18s 220ms/step - loss: 1.3423e-05 - accuracy: 1.0000 - val_loss: 0.0055 - val_accuracy: 0.9979\n",
      "Epoch 11/50\n",
      "83/83 [==============================] - 19s 233ms/step - loss: 9.8061e-06 - accuracy: 1.0000 - val_loss: 0.0057 - val_accuracy: 0.9979\n",
      "Epoch 12/50\n",
      "83/83 [==============================] - 19s 228ms/step - loss: 7.3595e-06 - accuracy: 1.0000 - val_loss: 0.0056 - val_accuracy: 0.9979\n",
      "Epoch 00012: early stopping\n",
      "4/4 [==============================] - 1s 188ms/step - loss: 2.0532e-04 - accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▎        | 3/22 [13:57<1:23:41, 264.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "84/84 [==============================] - 22s 258ms/step - loss: 0.4836 - accuracy: 0.7484 - val_loss: 0.2220 - val_accuracy: 0.9190\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/section_classification_models\\excluded_5\\assets\n",
      "Epoch 2/50\n",
      "84/84 [==============================] - 20s 233ms/step - loss: 0.1385 - accuracy: 0.9528 - val_loss: 0.0972 - val_accuracy: 0.9697\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/section_classification_models\\excluded_5\\assets\n",
      "Epoch 3/50\n",
      "84/84 [==============================] - 19s 231ms/step - loss: 0.0179 - accuracy: 0.9935 - val_loss: 0.0124 - val_accuracy: 0.9944\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/section_classification_models\\excluded_5\\assets\n",
      "Epoch 4/50\n",
      "84/84 [==============================] - 19s 231ms/step - loss: 0.0021 - accuracy: 0.9995 - val_loss: 0.0026 - val_accuracy: 0.9993\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/section_classification_models\\excluded_5\\assets\n",
      "Epoch 5/50\n",
      "84/84 [==============================] - 20s 232ms/step - loss: 4.6258e-04 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 0.9983\n",
      "Epoch 6/50\n",
      "84/84 [==============================] - 21s 255ms/step - loss: 6.2435e-05 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 0.9987\n",
      "Epoch 7/50\n",
      "84/84 [==============================] - 21s 248ms/step - loss: 2.5169e-05 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 0.9985\n",
      "Epoch 8/50\n",
      "84/84 [==============================] - 20s 237ms/step - loss: 1.2910e-05 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 0.9985\n",
      "Epoch 9/50\n",
      "84/84 [==============================] - 20s 241ms/step - loss: 8.7819e-06 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 0.9985\n",
      "Epoch 00009: early stopping\n",
      "3/3 [==============================] - 1s 108ms/step - loss: 3.0559e-06 - accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 4/22 [17:09<1:10:40, 235.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "84/84 [==============================] - 19s 224ms/step - loss: 0.4739 - accuracy: 0.7552 - val_loss: 0.1996 - val_accuracy: 0.9296\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/section_classification_models\\excluded_6\\assets\n",
      "Epoch 2/50\n",
      "84/84 [==============================] - 18s 216ms/step - loss: 0.1134 - accuracy: 0.9627 - val_loss: 0.0211 - val_accuracy: 0.9916\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/section_classification_models\\excluded_6\\assets\n",
      "Epoch 3/50\n",
      "84/84 [==============================] - 19s 225ms/step - loss: 0.0115 - accuracy: 0.9964 - val_loss: 0.0123 - val_accuracy: 0.9951\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/section_classification_models\\excluded_6\\assets\n",
      "Epoch 4/50\n",
      "84/84 [==============================] - 18s 217ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.0031 - val_accuracy: 0.9991\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/section_classification_models\\excluded_6\\assets\n",
      "Epoch 5/50\n",
      "84/84 [==============================] - 20s 233ms/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 0.0072 - val_accuracy: 0.9974\n",
      "Epoch 6/50\n",
      "84/84 [==============================] - 20s 233ms/step - loss: 0.0855 - accuracy: 0.9803 - val_loss: 0.0415 - val_accuracy: 0.9894\n",
      "Epoch 7/50\n",
      "84/84 [==============================] - 19s 228ms/step - loss: 0.0042 - accuracy: 0.9995 - val_loss: 0.0121 - val_accuracy: 0.9957\n",
      "Epoch 8/50\n",
      "84/84 [==============================] - 21s 249ms/step - loss: 1.8543e-04 - accuracy: 1.0000 - val_loss: 0.0113 - val_accuracy: 0.9965\n",
      "Epoch 9/50\n",
      "84/84 [==============================] - 19s 227ms/step - loss: 8.9798e-05 - accuracy: 1.0000 - val_loss: 0.0113 - val_accuracy: 0.9965\n",
      "Epoch 00009: early stopping\n",
      "3/3 [==============================] - 1s 183ms/step - loss: 1.1182e-11 - accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 5/22 [20:12<1:01:22, 216.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "84/84 [==============================] - 19s 226ms/step - loss: 0.5092 - accuracy: 0.7316 - val_loss: 0.2244 - val_accuracy: 0.9166\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/section_classification_models\\excluded_7\\assets\n",
      "Epoch 2/50\n",
      "84/84 [==============================] - 21s 243ms/step - loss: 0.1512 - accuracy: 0.9483 - val_loss: 0.0797 - val_accuracy: 0.9656\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/section_classification_models\\excluded_7\\assets\n",
      "Epoch 3/50\n",
      "84/84 [==============================] - 21s 247ms/step - loss: 0.0130 - accuracy: 0.9955 - val_loss: 0.0062 - val_accuracy: 0.9972\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/section_classification_models\\excluded_7\\assets\n",
      "Epoch 4/50\n",
      "84/84 [==============================] - 19s 222ms/step - loss: 0.0015 - accuracy: 0.9997 - val_loss: 0.0042 - val_accuracy: 0.9983\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/section_classification_models\\excluded_7\\assets\n",
      "Epoch 5/50\n",
      "84/84 [==============================] - 21s 244ms/step - loss: 6.3070e-04 - accuracy: 0.9999 - val_loss: 0.0096 - val_accuracy: 0.9970\n",
      "Epoch 6/50\n",
      "84/84 [==============================] - 21s 246ms/step - loss: 7.0598e-05 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 0.9983\n",
      "Epoch 7/50\n",
      "84/84 [==============================] - 20s 237ms/step - loss: 2.3960e-05 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 0.9983\n",
      "Epoch 8/50\n",
      "84/84 [==============================] - 19s 224ms/step - loss: 1.3279e-05 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 0.9983\n",
      "Epoch 9/50\n",
      "84/84 [==============================] - 19s 231ms/step - loss: 8.2062e-06 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 0.9981\n",
      "Epoch 10/50\n",
      "84/84 [==============================] - 21s 246ms/step - loss: 5.2326e-06 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 0.9981\n",
      "Epoch 11/50\n",
      "84/84 [==============================] - 20s 233ms/step - loss: 3.6621e-06 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 0.9981\n",
      "Epoch 00011: early stopping\n",
      "3/3 [==============================] - 1s 203ms/step - loss: 9.0675e-10 - accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 6/22 [24:01<58:55, 220.97s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "79/79 [==============================] - 19s 239ms/step - loss: 0.5033 - accuracy: 0.7416 - val_loss: 0.1865 - val_accuracy: 0.9444\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/section_classification_models\\excluded_8\\assets\n",
      "Epoch 2/50\n",
      "79/79 [==============================] - 19s 239ms/step - loss: 0.0457 - accuracy: 0.9855 - val_loss: 0.0126 - val_accuracy: 0.9956\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/section_classification_models\\excluded_8\\assets\n",
      "Epoch 3/50\n",
      "79/79 [==============================] - 20s 252ms/step - loss: 0.0055 - accuracy: 0.9983 - val_loss: 0.0102 - val_accuracy: 0.9964\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/section_classification_models\\excluded_8\\assets\n",
      "Epoch 4/50\n",
      "79/79 [==============================] - 18s 229ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.0126 - val_accuracy: 0.9956\n",
      "Epoch 5/50\n",
      "79/79 [==============================] - 19s 241ms/step - loss: 0.0023 - accuracy: 0.9993 - val_loss: 0.0207 - val_accuracy: 0.9943\n",
      "Epoch 6/50\n",
      "79/79 [==============================] - 18s 222ms/step - loss: 0.0017 - accuracy: 0.9996 - val_loss: 0.0030 - val_accuracy: 0.9986\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/section_classification_models\\excluded_8\\assets\n",
      "Epoch 7/50\n",
      "79/79 [==============================] - 19s 235ms/step - loss: 4.3292e-05 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 0.9980\n",
      "Epoch 8/50\n",
      "79/79 [==============================] - 19s 239ms/step - loss: 3.1176e-05 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 0.9984\n",
      "Epoch 9/50\n",
      "79/79 [==============================] - 18s 227ms/step - loss: 2.3354e-05 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 0.9980\n",
      "Epoch 10/50\n",
      "79/79 [==============================] - 19s 236ms/step - loss: 1.8557e-05 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 0.9982\n",
      "Epoch 11/50\n",
      "79/79 [==============================] - 19s 235ms/step - loss: 1.5120e-05 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 0.9982\n",
      "Epoch 00011: early stopping\n",
      "9/9 [==============================] - 2s 183ms/step - loss: 1.7209 - accuracy: 0.4838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 7/22 [27:38<54:56, 219.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "84/84 [==============================] - 21s 239ms/step - loss: 0.5196 - accuracy: 0.7166 - val_loss: 0.2394 - val_accuracy: 0.9189\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/section_classification_models\\excluded_9\\assets\n",
      "Epoch 2/50\n",
      "84/84 [==============================] - 20s 233ms/step - loss: 0.1812 - accuracy: 0.9364 - val_loss: 0.1108 - val_accuracy: 0.9600\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/section_classification_models\\excluded_9\\assets\n",
      "Epoch 3/50\n",
      "84/84 [==============================] - 21s 252ms/step - loss: 0.0245 - accuracy: 0.9931 - val_loss: 0.0152 - val_accuracy: 0.9946\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/section_classification_models\\excluded_9\\assets\n",
      "Epoch 4/50\n",
      "84/84 [==============================] - 20s 236ms/step - loss: 0.0032 - accuracy: 0.9992 - val_loss: 0.0097 - val_accuracy: 0.9968\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/section_classification_models\\excluded_9\\assets\n",
      "Epoch 5/50\n",
      "84/84 [==============================] - 20s 233ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 0.0056 - val_accuracy: 0.9978\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/section_classification_models\\excluded_9\\assets\n",
      "Epoch 6/50\n",
      "84/84 [==============================] - 20s 234ms/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 0.0124 - val_accuracy: 0.9946\n",
      "Epoch 7/50\n",
      "84/84 [==============================] - 20s 236ms/step - loss: 2.5283e-04 - accuracy: 0.9999 - val_loss: 0.0025 - val_accuracy: 0.9989\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/section_classification_models\\excluded_9\\assets\n",
      "Epoch 8/50\n",
      "84/84 [==============================] - 20s 234ms/step - loss: 3.4656e-05 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 0.9987\n",
      "Epoch 9/50\n",
      "84/84 [==============================] - 19s 230ms/step - loss: 2.6047e-05 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 0.9985\n",
      "Epoch 10/50\n",
      "84/84 [==============================] - 20s 242ms/step - loss: 1.9191e-05 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 0.9985\n",
      "Epoch 11/50\n",
      "84/84 [==============================] - 19s 232ms/step - loss: 1.1973e-05 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 0.9985\n",
      "Epoch 12/50\n",
      "84/84 [==============================] - 19s 228ms/step - loss: 8.1689e-06 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 0.9987\n",
      "Epoch 00012: early stopping\n",
      "3/3 [==============================] - 1s 180ms/step - loss: 9.2819e-04 - accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▋      | 8/22 [31:51<53:42, 230.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "83/83 [==============================] - 21s 255ms/step - loss: 0.4917 - accuracy: 0.7381 - val_loss: 0.2072 - val_accuracy: 0.9234\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/section_classification_models\\excluded_10\\assets\n",
      "Epoch 2/50\n",
      "83/83 [==============================] - 22s 257ms/step - loss: 0.1017 - accuracy: 0.9660 - val_loss: 0.0113 - val_accuracy: 0.9964\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/section_classification_models\\excluded_10\\assets\n",
      "Epoch 3/50\n",
      "83/83 [==============================] - 19s 228ms/step - loss: 0.0076 - accuracy: 0.9975 - val_loss: 0.0064 - val_accuracy: 0.9975\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/section_classification_models\\excluded_10\\assets\n",
      "Epoch 4/50\n",
      "83/83 [==============================] - 19s 228ms/step - loss: 0.0030 - accuracy: 0.9992 - val_loss: 0.0044 - val_accuracy: 0.9985\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/section_classification_models\\excluded_10\\assets\n",
      "Epoch 5/50\n",
      "83/83 [==============================] - 20s 236ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.0016 - val_accuracy: 0.9996\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/section_classification_models\\excluded_10\\assets\n",
      "Epoch 6/50\n",
      "83/83 [==============================] - 19s 230ms/step - loss: 9.5910e-05 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 0.9994\n",
      "Epoch 7/50\n",
      "83/83 [==============================] - 20s 237ms/step - loss: 3.2349e-05 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 0.9992\n",
      "Epoch 8/50\n",
      "83/83 [==============================] - 19s 233ms/step - loss: 1.9682e-05 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 0.9996\n",
      "Epoch 9/50\n",
      "83/83 [==============================] - 19s 234ms/step - loss: 1.0164e-05 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 0.9996\n",
      "Epoch 10/50\n",
      "83/83 [==============================] - 19s 232ms/step - loss: 5.2968e-06 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 0.9992\n",
      "Epoch 11/50\n",
      "83/83 [==============================] - 19s 233ms/step - loss: 3.5038e-06 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 0.9992\n",
      "Epoch 12/50\n",
      "83/83 [==============================] - 21s 250ms/step - loss: 2.3669e-06 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 0.9992\n",
      "Epoch 00012: early stopping\n",
      "4/4 [==============================] - 1s 194ms/step - loss: 0.1081 - accuracy: 0.9741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 9/22 [36:01<51:12, 236.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "81/81 [==============================] - 19s 231ms/step - loss: 0.5149 - accuracy: 0.7244 - val_loss: 0.2745 - val_accuracy: 0.9052\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/section_classification_models\\excluded_11\\assets\n",
      "Epoch 2/50\n",
      "81/81 [==============================] - 18s 227ms/step - loss: 0.1573 - accuracy: 0.9451 - val_loss: 0.0266 - val_accuracy: 0.9918\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/section_classification_models\\excluded_11\\assets\n",
      "Epoch 3/50\n",
      "81/81 [==============================] - 20s 240ms/step - loss: 0.0587 - accuracy: 0.9813 - val_loss: 0.0430 - val_accuracy: 0.9865\n",
      "Epoch 4/50\n",
      "81/81 [==============================] - 19s 235ms/step - loss: 0.0075 - accuracy: 0.9978 - val_loss: 0.0069 - val_accuracy: 0.9975\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/section_classification_models\\excluded_11\\assets\n",
      "Epoch 5/50\n",
      "81/81 [==============================] - 20s 241ms/step - loss: 0.0021 - accuracy: 0.9996 - val_loss: 0.0041 - val_accuracy: 0.9986\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/section_classification_models\\excluded_11\\assets\n",
      "Epoch 6/50\n",
      "81/81 [==============================] - 18s 229ms/step - loss: 9.8944e-04 - accuracy: 0.9999 - val_loss: 0.0041 - val_accuracy: 0.9986\n",
      "Epoch 7/50\n",
      "81/81 [==============================] - 20s 242ms/step - loss: 4.0905e-04 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 0.9988\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/section_classification_models\\excluded_11\\assets\n",
      "Epoch 8/50\n",
      "81/81 [==============================] - 20s 250ms/step - loss: 1.8083e-04 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 0.9982\n",
      "Epoch 9/50\n",
      "81/81 [==============================] - 19s 234ms/step - loss: 1.1926e-04 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 0.9990\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/section_classification_models\\excluded_11\\assets\n",
      "Epoch 10/50\n",
      "81/81 [==============================] - 19s 234ms/step - loss: 8.4943e-05 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 0.9990\n",
      "Epoch 11/50\n",
      "81/81 [==============================] - 19s 231ms/step - loss: 6.1904e-05 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 0.9990\n",
      "Epoch 12/50\n",
      "81/81 [==============================] - 18s 223ms/step - loss: 1.5452e-05 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 0.9988\n",
      "Epoch 13/50\n",
      "81/81 [==============================] - 19s 232ms/step - loss: 5.1464e-06 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 0.9986\n",
      "Epoch 14/50\n",
      "81/81 [==============================] - 18s 224ms/step - loss: 3.5369e-06 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 0.9986\n",
      "Epoch 00014: early stopping\n",
      "7/7 [==============================] - 2s 206ms/step - loss: 4.1207e-08 - accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 10/22 [40:42<50:02, 250.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "78/78 [==============================] - 20s 252ms/step - loss: 0.5676 - accuracy: 0.6899 - val_loss: 0.3265 - val_accuracy: 0.9149\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/section_classification_models\\excluded_12\\assets\n",
      "Epoch 2/50\n",
      "78/78 [==============================] - 18s 234ms/step - loss: 0.1530 - accuracy: 0.9559 - val_loss: 0.0490 - val_accuracy: 0.9865\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/section_classification_models\\excluded_12\\assets\n",
      "Epoch 3/50\n",
      "78/78 [==============================] - 18s 227ms/step - loss: 0.0180 - accuracy: 0.9952 - val_loss: 0.0110 - val_accuracy: 0.9962\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/section_classification_models\\excluded_12\\assets\n",
      "Epoch 4/50\n",
      "78/78 [==============================] - 18s 226ms/step - loss: 0.0052 - accuracy: 0.9986 - val_loss: 0.0067 - val_accuracy: 0.9978\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/section_classification_models\\excluded_12\\assets\n",
      "Epoch 5/50\n",
      "78/78 [==============================] - 18s 233ms/step - loss: 0.0023 - accuracy: 0.9995 - val_loss: 0.0057 - val_accuracy: 0.9984\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/section_classification_models\\excluded_12\\assets\n",
      "Epoch 6/50\n",
      "78/78 [==============================] - 20s 249ms/step - loss: 7.1689e-04 - accuracy: 0.9999 - val_loss: 0.0053 - val_accuracy: 0.9984\n",
      "Epoch 7/50\n",
      "78/78 [==============================] - 18s 233ms/step - loss: 3.5671e-04 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 0.9984\n",
      "Epoch 8/50\n",
      "78/78 [==============================] - 19s 240ms/step - loss: 2.3844e-04 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 0.9988\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/section_classification_models\\excluded_12\\assets\n",
      "Epoch 9/50\n",
      "78/78 [==============================] - 18s 232ms/step - loss: 1.7872e-04 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 0.9986\n",
      "Epoch 10/50\n",
      "78/78 [==============================] - 18s 234ms/step - loss: 1.3216e-04 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 0.9984\n",
      "Epoch 11/50\n",
      "78/78 [==============================] - 19s 238ms/step - loss: 1.0295e-04 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 0.9986\n",
      "Epoch 12/50\n",
      "78/78 [==============================] - 19s 240ms/step - loss: 6.7681e-05 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 0.9988\n",
      "Epoch 13/50\n",
      "78/78 [==============================] - 18s 229ms/step - loss: 2.1708e-05 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 0.9986\n",
      "Epoch 14/50\n",
      "78/78 [==============================] - 20s 253ms/step - loss: 1.0137e-05 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 0.9986\n",
      "Epoch 00014: early stopping\n",
      "11/11 [==============================] - 2s 204ms/step - loss: 9.7051e-06 - accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 11/22 [45:18<47:17, 257.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "82/82 [==============================] - 21s 248ms/step - loss: 0.4960 - accuracy: 0.7484 - val_loss: 0.2452 - val_accuracy: 0.9212\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/section_classification_models\\excluded_13\\assets\n",
      "Epoch 2/50\n",
      "82/82 [==============================] - 20s 247ms/step - loss: 0.0501 - accuracy: 0.9858 - val_loss: 0.0085 - val_accuracy: 0.9966\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/section_classification_models\\excluded_13\\assets\n",
      "Epoch 3/50\n",
      "82/82 [==============================] - 21s 249ms/step - loss: 0.0054 - accuracy: 0.9984 - val_loss: 0.0038 - val_accuracy: 0.9994\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/section_classification_models\\excluded_13\\assets\n",
      "Epoch 4/50\n",
      "82/82 [==============================] - 21s 254ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.0022 - val_accuracy: 0.9989\n",
      "Epoch 5/50\n",
      "82/82 [==============================] - 19s 237ms/step - loss: 3.9839e-04 - accuracy: 0.9999 - val_loss: 0.0024 - val_accuracy: 0.9989\n",
      "Epoch 6/50\n",
      "82/82 [==============================] - 19s 237ms/step - loss: 6.4034e-05 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 0.9992\n",
      "Epoch 7/50\n",
      "82/82 [==============================] - 19s 232ms/step - loss: 3.5974e-05 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 0.9987\n",
      "Epoch 8/50\n",
      "82/82 [==============================] - 21s 259ms/step - loss: 2.1836e-05 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 0.9987\n",
      "Epoch 9/50\n",
      "82/82 [==============================] - 19s 236ms/step - loss: 1.5023e-05 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 0.9990\n",
      "Epoch 10/50\n",
      "82/82 [==============================] - 21s 259ms/step - loss: 8.8376e-06 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 0.9992\n",
      "Epoch 11/50\n",
      "82/82 [==============================] - 20s 242ms/step - loss: 5.2457e-06 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 0.9992\n",
      "Epoch 12/50\n",
      "82/82 [==============================] - 19s 234ms/step - loss: 3.5854e-06 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 0.9990\n",
      "Epoch 00012: early stopping\n",
      "5/5 [==============================] - 1s 195ms/step - loss: 2.3110e-04 - accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 12/22 [49:28<42:35, 255.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "80/80 [==============================] - 21s 253ms/step - loss: 0.5542 - accuracy: 0.6852 - val_loss: 0.3119 - val_accuracy: 0.9180\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/section_classification_models\\excluded_14\\assets\n",
      "Epoch 2/50\n",
      "80/80 [==============================] - 20s 253ms/step - loss: 0.2230 - accuracy: 0.9267 - val_loss: 0.1404 - val_accuracy: 0.9479\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/section_classification_models\\excluded_14\\assets\n",
      "Epoch 3/50\n",
      "80/80 [==============================] - 19s 233ms/step - loss: 0.0365 - accuracy: 0.9884 - val_loss: 0.0135 - val_accuracy: 0.9959\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/section_classification_models\\excluded_14\\assets\n",
      "Epoch 4/50\n",
      "80/80 [==============================] - 20s 246ms/step - loss: 0.0043 - accuracy: 0.9990 - val_loss: 0.0158 - val_accuracy: 0.9939\n",
      "Epoch 5/50\n",
      "80/80 [==============================] - 19s 241ms/step - loss: 0.0028 - accuracy: 0.9988 - val_loss: 0.0119 - val_accuracy: 0.9967\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/section_classification_models\\excluded_14\\assets\n",
      "Epoch 6/50\n",
      "80/80 [==============================] - 18s 231ms/step - loss: 1.0152e-04 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9990\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/section_classification_models\\excluded_14\\assets\n",
      "Epoch 7/50\n",
      "80/80 [==============================] - 18s 231ms/step - loss: 4.8936e-05 - accuracy: 1.0000 - val_loss: 0.0052 - val_accuracy: 0.9982\n",
      "Epoch 8/50\n",
      "80/80 [==============================] - 18s 228ms/step - loss: 2.4064e-05 - accuracy: 1.0000 - val_loss: 0.0060 - val_accuracy: 0.9980\n",
      "Epoch 9/50\n",
      "80/80 [==============================] - 19s 233ms/step - loss: 1.2158e-05 - accuracy: 1.0000 - val_loss: 0.0059 - val_accuracy: 0.9982\n",
      "Epoch 10/50\n",
      "80/80 [==============================] - 18s 228ms/step - loss: 5.9955e-06 - accuracy: 1.0000 - val_loss: 0.0069 - val_accuracy: 0.9982\n",
      "Epoch 11/50\n",
      "80/80 [==============================] - 18s 224ms/step - loss: 3.4967e-06 - accuracy: 1.0000 - val_loss: 0.0066 - val_accuracy: 0.9982\n",
      "Epoch 00011: early stopping\n",
      "8/8 [==============================] - 2s 190ms/step - loss: 0.0040 - accuracy: 0.9985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 13/22 [53:10<36:48, 245.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "82/82 [==============================] - 20s 238ms/step - loss: 0.5082 - accuracy: 0.7264 - val_loss: 0.2297 - val_accuracy: 0.9306\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/section_classification_models\\excluded_15\\assets\n",
      "Epoch 2/50\n",
      "82/82 [==============================] - 20s 242ms/step - loss: 0.1877 - accuracy: 0.9349 - val_loss: 0.1778 - val_accuracy: 0.9353\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/section_classification_models\\excluded_15\\assets\n",
      "Epoch 3/50\n",
      "82/82 [==============================] - 19s 224ms/step - loss: 0.1176 - accuracy: 0.9401 - val_loss: 0.0646 - val_accuracy: 0.9349\n",
      "Epoch 4/50\n",
      "82/82 [==============================] - 19s 234ms/step - loss: 0.0369 - accuracy: 0.9882 - val_loss: 0.0096 - val_accuracy: 0.9977\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/section_classification_models\\excluded_15\\assets\n",
      "Epoch 5/50\n",
      "82/82 [==============================] - 20s 237ms/step - loss: 0.0030 - accuracy: 0.9992 - val_loss: 0.0025 - val_accuracy: 0.9990\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/section_classification_models\\excluded_15\\assets\n",
      "Epoch 6/50\n",
      "82/82 [==============================] - 20s 245ms/step - loss: 0.0013 - accuracy: 0.9997 - val_loss: 0.0104 - val_accuracy: 0.9960\n",
      "Epoch 7/50\n",
      "82/82 [==============================] - 20s 241ms/step - loss: 0.0010 - accuracy: 0.9997 - val_loss: 0.0040 - val_accuracy: 0.9987\n",
      "Epoch 8/50\n",
      "82/82 [==============================] - 19s 236ms/step - loss: 8.6937e-04 - accuracy: 0.9996 - val_loss: 9.1090e-04 - val_accuracy: 0.9998\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/section_classification_models\\excluded_15\\assets\n",
      "Epoch 9/50\n",
      "82/82 [==============================] - 20s 244ms/step - loss: 2.8290e-05 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 0.9992\n",
      "Epoch 10/50\n",
      "82/82 [==============================] - 21s 252ms/step - loss: 1.8612e-05 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 0.9994\n",
      "Epoch 11/50\n",
      "82/82 [==============================] - 20s 242ms/step - loss: 1.3565e-05 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 0.9994\n",
      "Epoch 12/50\n",
      "82/82 [==============================] - 20s 244ms/step - loss: 8.9656e-06 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 0.9996\n",
      "Epoch 13/50\n",
      "82/82 [==============================] - 20s 243ms/step - loss: 4.7706e-06 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 0.9996\n",
      "Epoch 00013: early stopping\n",
      "5/5 [==============================] - 1s 187ms/step - loss: 7.2122 - accuracy: 0.2690\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▎   | 14/22 [57:39<33:41, 252.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "82/82 [==============================] - 19s 233ms/step - loss: 0.5160 - accuracy: 0.7265 - val_loss: 0.2344 - val_accuracy: 0.9170\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/section_classification_models\\excluded_16\\assets\n",
      "Epoch 2/50\n",
      "82/82 [==============================] - 19s 224ms/step - loss: 0.1658 - accuracy: 0.9403 - val_loss: 0.0815 - val_accuracy: 0.9664\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/section_classification_models\\excluded_16\\assets\n",
      "Epoch 3/50\n",
      "82/82 [==============================] - 18s 222ms/step - loss: 0.0230 - accuracy: 0.9925 - val_loss: 0.0138 - val_accuracy: 0.9956\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/section_classification_models\\excluded_16\\assets\n",
      "Epoch 4/50\n",
      "82/82 [==============================] - 20s 242ms/step - loss: 0.0031 - accuracy: 0.9992 - val_loss: 0.0343 - val_accuracy: 0.9889\n",
      "Epoch 5/50\n",
      "82/82 [==============================] - 20s 245ms/step - loss: 7.4006e-04 - accuracy: 0.9998 - val_loss: 0.0081 - val_accuracy: 0.9973\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/section_classification_models\\excluded_16\\assets\n",
      "Epoch 6/50\n",
      "82/82 [==============================] - 20s 237ms/step - loss: 1.0519e-04 - accuracy: 1.0000 - val_loss: 0.0104 - val_accuracy: 0.9977\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/section_classification_models\\excluded_16\\assets\n",
      "Epoch 7/50\n",
      "82/82 [==============================] - 20s 240ms/step - loss: 4.5953e-05 - accuracy: 1.0000 - val_loss: 0.0078 - val_accuracy: 0.9975\n",
      "Epoch 8/50\n",
      "82/82 [==============================] - 20s 247ms/step - loss: 1.4949e-05 - accuracy: 1.0000 - val_loss: 0.0081 - val_accuracy: 0.9975\n",
      "Epoch 9/50\n",
      "82/82 [==============================] - 19s 237ms/step - loss: 9.2085e-06 - accuracy: 1.0000 - val_loss: 0.0084 - val_accuracy: 0.9975\n",
      "Epoch 10/50\n",
      "82/82 [==============================] - 20s 240ms/step - loss: 6.6231e-06 - accuracy: 1.0000 - val_loss: 0.0084 - val_accuracy: 0.9977\n",
      "Epoch 11/50\n",
      "82/82 [==============================] - 20s 246ms/step - loss: 5.2191e-06 - accuracy: 1.0000 - val_loss: 0.0086 - val_accuracy: 0.9979\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/section_classification_models\\excluded_16\\assets\n",
      "Epoch 12/50\n",
      "82/82 [==============================] - 19s 236ms/step - loss: 4.1229e-06 - accuracy: 1.0000 - val_loss: 0.0089 - val_accuracy: 0.9977\n",
      "Epoch 00012: early stopping\n",
      "6/6 [==============================] - 1s 122ms/step - loss: 1.7254 - accuracy: 0.7446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 15/22 [1:01:48<29:20, 251.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "83/83 [==============================] - 21s 250ms/step - loss: 0.5119 - accuracy: 0.7273 - val_loss: 0.2171 - val_accuracy: 0.9176\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/section_classification_models\\excluded_18\\assets\n",
      "Epoch 2/50\n",
      "83/83 [==============================] - 20s 241ms/step - loss: 0.1294 - accuracy: 0.9554 - val_loss: 0.0284 - val_accuracy: 0.9907\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/section_classification_models\\excluded_18\\assets\n",
      "Epoch 3/50\n",
      "83/83 [==============================] - 20s 238ms/step - loss: 0.0110 - accuracy: 0.9966 - val_loss: 0.0305 - val_accuracy: 0.9886\n",
      "Epoch 4/50\n",
      "83/83 [==============================] - 19s 232ms/step - loss: 0.0101 - accuracy: 0.9964 - val_loss: 0.0135 - val_accuracy: 0.9966\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/section_classification_models\\excluded_18\\assets\n",
      "Epoch 5/50\n",
      "83/83 [==============================] - 20s 240ms/step - loss: 9.8681e-04 - accuracy: 0.9997 - val_loss: 0.0085 - val_accuracy: 0.9981\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/section_classification_models\\excluded_18\\assets\n",
      "Epoch 6/50\n",
      "83/83 [==============================] - 20s 236ms/step - loss: 1.1439e-04 - accuracy: 1.0000 - val_loss: 0.0065 - val_accuracy: 0.9985\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/section_classification_models\\excluded_18\\assets\n",
      "Epoch 7/50\n",
      "83/83 [==============================] - 20s 237ms/step - loss: 3.2478e-05 - accuracy: 1.0000 - val_loss: 0.0069 - val_accuracy: 0.9985\n",
      "Epoch 8/50\n",
      "83/83 [==============================] - 20s 246ms/step - loss: 1.0781e-05 - accuracy: 1.0000 - val_loss: 0.0069 - val_accuracy: 0.9989\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/section_classification_models\\excluded_18\\assets\n",
      "Epoch 9/50\n",
      "83/83 [==============================] - 21s 254ms/step - loss: 6.5657e-06 - accuracy: 1.0000 - val_loss: 0.0072 - val_accuracy: 0.9989\n",
      "Epoch 10/50\n",
      "83/83 [==============================] - 20s 246ms/step - loss: 4.6934e-06 - accuracy: 1.0000 - val_loss: 0.0072 - val_accuracy: 0.9987\n",
      "Epoch 11/50\n",
      "83/83 [==============================] - 20s 235ms/step - loss: 3.5790e-06 - accuracy: 1.0000 - val_loss: 0.0074 - val_accuracy: 0.9989\n",
      "Epoch 00011: early stopping\n",
      "4/4 [==============================] - 1s 217ms/step - loss: 0.0093 - accuracy: 0.9969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 16/22 [1:05:43<24:40, 246.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "84/84 [==============================] - 21s 246ms/step - loss: 0.5051 - accuracy: 0.7361 - val_loss: 0.2785 - val_accuracy: 0.8979\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/section_classification_models\\excluded_19\\assets\n",
      "Epoch 2/50\n",
      "84/84 [==============================] - 20s 234ms/step - loss: 0.1819 - accuracy: 0.9357 - val_loss: 0.0719 - val_accuracy: 0.9792\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/section_classification_models\\excluded_19\\assets\n",
      "Epoch 3/50\n",
      "84/84 [==============================] - 20s 241ms/step - loss: 0.0217 - accuracy: 0.9935 - val_loss: 0.0081 - val_accuracy: 0.9964\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/section_classification_models\\excluded_19\\assets\n",
      "Epoch 4/50\n",
      "84/84 [==============================] - 21s 245ms/step - loss: 0.0033 - accuracy: 0.9991 - val_loss: 0.0070 - val_accuracy: 0.9972\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/section_classification_models\\excluded_19\\assets\n",
      "Epoch 5/50\n",
      "84/84 [==============================] - 19s 228ms/step - loss: 9.8233e-04 - accuracy: 0.9998 - val_loss: 0.0051 - val_accuracy: 0.9978\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/section_classification_models\\excluded_19\\assets\n",
      "Epoch 6/50\n",
      "84/84 [==============================] - 19s 226ms/step - loss: 1.0236e-04 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 0.9979\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/section_classification_models\\excluded_19\\assets\n",
      "Epoch 7/50\n",
      "84/84 [==============================] - 19s 221ms/step - loss: 4.0579e-05 - accuracy: 1.0000 - val_loss: 0.0057 - val_accuracy: 0.9979\n",
      "Epoch 8/50\n",
      "84/84 [==============================] - 19s 227ms/step - loss: 1.7281e-05 - accuracy: 1.0000 - val_loss: 0.0064 - val_accuracy: 0.9978\n",
      "Epoch 9/50\n",
      "84/84 [==============================] - 21s 246ms/step - loss: 9.6547e-06 - accuracy: 1.0000 - val_loss: 0.0060 - val_accuracy: 0.9979\n",
      "Epoch 10/50\n",
      "84/84 [==============================] - 20s 239ms/step - loss: 5.8967e-06 - accuracy: 1.0000 - val_loss: 0.0064 - val_accuracy: 0.9978\n",
      "Epoch 00010: early stopping\n",
      "3/3 [==============================] - 1s 167ms/step - loss: 0.0233 - accuracy: 0.9897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 17/22 [1:09:16<19:42, 236.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "82/82 [==============================] - 21s 248ms/step - loss: 0.4989 - accuracy: 0.7427 - val_loss: 0.1954 - val_accuracy: 0.9264\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/section_classification_models\\excluded_20\\assets\n",
      "Epoch 2/50\n",
      "82/82 [==============================] - 21s 249ms/step - loss: 0.0755 - accuracy: 0.9742 - val_loss: 0.0239 - val_accuracy: 0.9914\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/section_classification_models\\excluded_20\\assets\n",
      "Epoch 3/50\n",
      "82/82 [==============================] - 20s 242ms/step - loss: 0.0040 - accuracy: 0.9987 - val_loss: 0.0047 - val_accuracy: 0.9983\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/section_classification_models\\excluded_20\\assets\n",
      "Epoch 4/50\n",
      "82/82 [==============================] - 21s 258ms/step - loss: 0.0472 - accuracy: 0.9866 - val_loss: 0.0107 - val_accuracy: 0.9962\n",
      "Epoch 5/50\n",
      "82/82 [==============================] - 19s 236ms/step - loss: 0.0014 - accuracy: 0.9999 - val_loss: 0.0032 - val_accuracy: 0.9992\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/section_classification_models\\excluded_20\\assets\n",
      "Epoch 6/50\n",
      "82/82 [==============================] - 19s 231ms/step - loss: 5.7668e-04 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 0.9992\n",
      "Epoch 7/50\n",
      "82/82 [==============================] - 21s 252ms/step - loss: 3.0970e-04 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 0.9994\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/section_classification_models\\excluded_20\\assets\n",
      "Epoch 8/50\n",
      "82/82 [==============================] - 19s 230ms/step - loss: 1.8090e-04 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 0.9994\n",
      "Epoch 9/50\n",
      "82/82 [==============================] - 20s 241ms/step - loss: 1.2769e-04 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 0.9994\n",
      "Epoch 10/50\n",
      "82/82 [==============================] - 20s 248ms/step - loss: 9.2165e-05 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 0.9994\n",
      "Epoch 11/50\n",
      "82/82 [==============================] - 20s 246ms/step - loss: 7.1416e-05 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 0.9994\n",
      "Epoch 12/50\n",
      "82/82 [==============================] - 19s 232ms/step - loss: 5.8000e-05 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 0.9992\n",
      "Epoch 13/50\n",
      "82/82 [==============================] - 23s 283ms/step - loss: 4.7062e-05 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 0.9994\n",
      "Epoch 14/50\n",
      "82/82 [==============================] - 19s 235ms/step - loss: 3.8788e-05 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 0.9994\n",
      "Epoch 15/50\n",
      "82/82 [==============================] - 20s 239ms/step - loss: 3.2906e-05 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 0.9994\n",
      "Epoch 16/50\n",
      "82/82 [==============================] - 20s 246ms/step - loss: 2.8030e-05 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 0.9994\n",
      "Epoch 17/50\n",
      "82/82 [==============================] - 19s 232ms/step - loss: 2.4322e-05 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 0.9994\n",
      "Epoch 18/50\n",
      "82/82 [==============================] - 19s 238ms/step - loss: 2.1208e-05 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 0.9994\n",
      "Epoch 19/50\n",
      "82/82 [==============================] - 20s 246ms/step - loss: 1.8581e-05 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 0.9994\n",
      "Epoch 20/50\n",
      "82/82 [==============================] - 19s 229ms/step - loss: 1.6444e-05 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 0.9994\n",
      "Epoch 21/50\n",
      "82/82 [==============================] - 19s 230ms/step - loss: 1.4650e-05 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 0.9994\n",
      "Epoch 22/50\n",
      "82/82 [==============================] - 19s 230ms/step - loss: 1.3059e-05 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 0.9994\n",
      "Epoch 23/50\n",
      "82/82 [==============================] - 20s 246ms/step - loss: 1.1776e-05 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 0.9994\n",
      "Epoch 00023: early stopping\n",
      "6/6 [==============================] - 1s 188ms/step - loss: 1.8536 - accuracy: 0.5568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 18/22 [1:17:07<20:27, 306.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "81/81 [==============================] - 21s 250ms/step - loss: 0.4556 - accuracy: 0.7668 - val_loss: 0.1583 - val_accuracy: 0.9496\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/section_classification_models\\excluded_21\\assets\n",
      "Epoch 2/50\n",
      "81/81 [==============================] - 19s 231ms/step - loss: 0.0649 - accuracy: 0.9806 - val_loss: 0.0059 - val_accuracy: 0.9979\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/section_classification_models\\excluded_21\\assets\n",
      "Epoch 3/50\n",
      "81/81 [==============================] - 19s 231ms/step - loss: 0.0067 - accuracy: 0.9983 - val_loss: 0.0021 - val_accuracy: 0.9994\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/section_classification_models\\excluded_21\\assets\n",
      "Epoch 4/50\n",
      "81/81 [==============================] - 20s 244ms/step - loss: 5.6272e-04 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 0.9992\n",
      "Epoch 5/50\n",
      "81/81 [==============================] - 18s 220ms/step - loss: 7.3329e-05 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 0.9990\n",
      "Epoch 6/50\n",
      "81/81 [==============================] - 20s 246ms/step - loss: 3.2703e-05 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 0.9992\n",
      "Epoch 7/50\n",
      "81/81 [==============================] - 19s 235ms/step - loss: 1.6284e-05 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 0.9990\n",
      "Epoch 8/50\n",
      "81/81 [==============================] - 19s 236ms/step - loss: 8.6455e-06 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 0.9990\n",
      "Epoch 9/50\n",
      "81/81 [==============================] - 18s 226ms/step - loss: 5.1968e-06 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 0.9990\n",
      "Epoch 00009: early stopping\n",
      "7/7 [==============================] - 2s 205ms/step - loss: 7.6226 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▋ | 19/22 [1:20:08<13:27, 269.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "81/81 [==============================] - 21s 250ms/step - loss: 0.5258 - accuracy: 0.7326 - val_loss: 0.2764 - val_accuracy: 0.9448\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/section_classification_models\\excluded_23\\assets\n",
      "Epoch 2/50\n",
      "81/81 [==============================] - 21s 255ms/step - loss: 0.0858 - accuracy: 0.9768 - val_loss: 0.0221 - val_accuracy: 0.9917\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/section_classification_models\\excluded_23\\assets\n",
      "Epoch 3/50\n",
      "81/81 [==============================] - 19s 227ms/step - loss: 0.0069 - accuracy: 0.9978 - val_loss: 0.0052 - val_accuracy: 0.9983\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/section_classification_models\\excluded_23\\assets\n",
      "Epoch 4/50\n",
      "81/81 [==============================] - 19s 228ms/step - loss: 0.0016 - accuracy: 0.9997 - val_loss: 0.0038 - val_accuracy: 0.9983\n",
      "Epoch 5/50\n",
      "81/81 [==============================] - 20s 243ms/step - loss: 4.6780e-04 - accuracy: 0.9999 - val_loss: 0.0031 - val_accuracy: 0.9986\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/section_classification_models\\excluded_23\\assets\n",
      "Epoch 6/50\n",
      "81/81 [==============================] - 21s 259ms/step - loss: 1.4171e-04 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 0.9984\n",
      "Epoch 7/50\n",
      "81/81 [==============================] - 18s 222ms/step - loss: 9.7680e-05 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 0.9988\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/section_classification_models\\excluded_23\\assets\n",
      "Epoch 8/50\n",
      "81/81 [==============================] - 19s 238ms/step - loss: 4.9928e-05 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 0.9984\n",
      "Epoch 9/50\n",
      "81/81 [==============================] - 19s 240ms/step - loss: 3.5388e-05 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 0.9990\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/section_classification_models\\excluded_23\\assets\n",
      "Epoch 10/50\n",
      "81/81 [==============================] - 20s 242ms/step - loss: 2.7004e-05 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 0.9983\n",
      "Epoch 11/50\n",
      "81/81 [==============================] - 19s 229ms/step - loss: 2.1705e-05 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 0.9988\n",
      "Epoch 12/50\n",
      "81/81 [==============================] - 19s 229ms/step - loss: 1.7313e-05 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 0.9986\n",
      "Epoch 13/50\n",
      "81/81 [==============================] - 19s 238ms/step - loss: 1.4130e-05 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 0.9986\n",
      "Epoch 14/50\n",
      "81/81 [==============================] - 19s 237ms/step - loss: 1.1882e-05 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 0.9986\n",
      "Epoch 00014: early stopping\n",
      "7/7 [==============================] - 1s 175ms/step - loss: 0.2137 - accuracy: 0.9581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 20/22 [1:24:55<09:08, 274.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "82/82 [==============================] - 20s 241ms/step - loss: 0.5100 - accuracy: 0.7315 - val_loss: 0.2395 - val_accuracy: 0.9085\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/section_classification_models\\excluded_25\\assets\n",
      "Epoch 2/50\n",
      "82/82 [==============================] - 19s 237ms/step - loss: 0.1737 - accuracy: 0.9374 - val_loss: 0.0616 - val_accuracy: 0.9834\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/section_classification_models\\excluded_25\\assets\n",
      "Epoch 3/50\n",
      "82/82 [==============================] - 19s 235ms/step - loss: 0.0209 - accuracy: 0.9933 - val_loss: 0.0066 - val_accuracy: 0.9977\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/section_classification_models\\excluded_25\\assets\n",
      "Epoch 4/50\n",
      "82/82 [==============================] - 21s 252ms/step - loss: 0.0034 - accuracy: 0.9988 - val_loss: 0.0091 - val_accuracy: 0.9969\n",
      "Epoch 5/50\n",
      "82/82 [==============================] - 20s 246ms/step - loss: 3.7195e-04 - accuracy: 0.9999 - val_loss: 0.0029 - val_accuracy: 0.9987\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/section_classification_models\\excluded_25\\assets\n",
      "Epoch 6/50\n",
      "82/82 [==============================] - 20s 245ms/step - loss: 2.8606e-04 - accuracy: 0.9999 - val_loss: 0.0208 - val_accuracy: 0.9948\n",
      "Epoch 7/50\n",
      "82/82 [==============================] - 20s 246ms/step - loss: 6.4521e-04 - accuracy: 0.9999 - val_loss: 0.0050 - val_accuracy: 0.9987\n",
      "Epoch 8/50\n",
      "82/82 [==============================] - 19s 233ms/step - loss: 1.9996e-05 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 0.9989\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/section_classification_models\\excluded_25\\assets\n",
      "Epoch 9/50\n",
      "82/82 [==============================] - 19s 236ms/step - loss: 1.3833e-05 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 0.9989\n",
      "Epoch 10/50\n",
      "82/82 [==============================] - 20s 237ms/step - loss: 1.1699e-05 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 0.9989\n",
      "Epoch 00010: early stopping\n",
      "5/5 [==============================] - 1s 199ms/step - loss: 1.4112e-04 - accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 21/22 [1:28:26<04:15, 255.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "79/79 [==============================] - 19s 240ms/step - loss: 0.5007 - accuracy: 0.7376 - val_loss: 0.2570 - val_accuracy: 0.9208\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/section_classification_models\\excluded_29\\assets\n",
      "Epoch 2/50\n",
      "79/79 [==============================] - 19s 235ms/step - loss: 0.1041 - accuracy: 0.9658 - val_loss: 0.0111 - val_accuracy: 0.9958\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/section_classification_models\\excluded_29\\assets\n",
      "Epoch 3/50\n",
      "79/79 [==============================] - 19s 235ms/step - loss: 0.0090 - accuracy: 0.9970 - val_loss: 0.0070 - val_accuracy: 0.9978\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/section_classification_models\\excluded_29\\assets\n",
      "Epoch 4/50\n",
      "79/79 [==============================] - 19s 240ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.0054 - val_accuracy: 0.9982\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/section_classification_models\\excluded_29\\assets\n",
      "Epoch 5/50\n",
      "79/79 [==============================] - 18s 230ms/step - loss: 1.7519e-04 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 0.9994\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/section_classification_models\\excluded_29\\assets\n",
      "Epoch 6/50\n",
      "79/79 [==============================] - 19s 236ms/step - loss: 8.0352e-05 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 0.9994\n",
      "Epoch 7/50\n",
      "79/79 [==============================] - 19s 236ms/step - loss: 3.1013e-05 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 0.9994\n",
      "Epoch 8/50\n",
      "79/79 [==============================] - 19s 242ms/step - loss: 1.9400e-05 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 0.9994\n",
      "Epoch 9/50\n",
      "79/79 [==============================] - 19s 246ms/step - loss: 1.3619e-05 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 0.9994\n",
      "Epoch 10/50\n",
      "79/79 [==============================] - 20s 258ms/step - loss: 9.6568e-06 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 0.9994\n",
      "Epoch 00010: early stopping\n",
      "9/9 [==============================] - 2s 216ms/step - loss: 0.0159 - accuracy: 0.9964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [1:31:50<00:00, 250.46s/it]\n"
     ]
    }
   ],
   "source": [
    "# Loop over each sample number\n",
    "for exclude_sample in tqdm(np.unique(sample_numbers)):\n",
    "  # Clear graph\n",
    "  K.clear_session()\n",
    "  gc.collect()\n",
    "\n",
    "  # Create filter for training data\n",
    "  train_filter = (sample_numbers != exclude_sample)\n",
    "\n",
    "  # Get indexes of all data\n",
    "  indexes = np.arange(len(sample_numbers))\n",
    "\n",
    "  # Get indexes of training data\n",
    "  train_indexes = indexes[train_filter]\n",
    "\n",
    "  # Get indexes of training and validation data\n",
    "  train_indexes, val_indexes = train_test_split(train_indexes,\n",
    "                                                test_size=0.2,\n",
    "                                                random_state=0,\n",
    "                                                stratify=labels[train_filter])\n",
    "\n",
    "  # Create data generators\n",
    "  training_generator = create_ds(train_indexes, BATCH_SIZE)\n",
    "  validation_generator = create_ds(val_indexes, BATCH_SIZE)\n",
    "  test_generator = create_ds(indexes[~train_filter], BATCH_SIZE)\n",
    "\n",
    "  # Create Callback to save the best model\n",
    "  checkpoint_filepath = os.path.join(MODELS_PATH, f\"excluded_{exclude_sample}/\")\n",
    "  model_checkpoint_callback = callbacks.ModelCheckpoint(\n",
    "      filepath=checkpoint_filepath,\n",
    "      save_weights_only=False,\n",
    "      monitor=\"val_accuracy\",\n",
    "      mode=\"max\",\n",
    "      save_best_only=True)\n",
    "  \n",
    "  # Create Callback for model early stopping\n",
    "  model_es_callback = callbacks.EarlyStopping(\n",
    "      monitor='val_loss', mode='min', verbose=1, patience=5, min_delta=0.0001)\n",
    "\n",
    "  # Create classification model\n",
    "  classification_model = get_model()\n",
    "\n",
    "  # Compile the classification model\n",
    "  optimizer = optimizers.Adam(learning_rate=LEARNING_RATE)\n",
    "  classification_model.compile(\n",
    "      optimizer, loss=losses.BinaryCrossentropy(), metrics=[\"accuracy\"])\n",
    "\n",
    "  # Train the classification model\n",
    "  history = classification_model.fit(\n",
    "      x=training_generator,\n",
    "      validation_data=validation_generator,\n",
    "      epochs=EPHOCS,\n",
    "      callbacks=[model_checkpoint_callback, model_es_callback])\n",
    "\n",
    "  # Load the best saved \n",
    "  classification_model = tf.keras.models.load_model(checkpoint_filepath)\n",
    "\n",
    "  # Evalute the classification model on test set\n",
    "  test_eval = classification_model.evaluate(x=test_generator)\n",
    "\n",
    "  # Clean model for next iteration\n",
    "  classification_model = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8526fece",
   "metadata": {},
   "source": [
    "### ***LOOCV predictions:***\n",
    "\n",
    "Next, let\"s get predictions for each LOOCV for evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eafba22d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 6/22 [00:15<00:39,  2.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 14 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000230CA11F430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [01:07<00:00,  3.05s/it]\n"
     ]
    }
   ],
   "source": [
    "# Define dict for saving predictions and true labels\n",
    "predictions = {}\n",
    "true_labels = {}\n",
    "\n",
    "# Loop over each sample number\n",
    "for exclude_sample in tqdm(np.unique(sample_numbers)):\n",
    "  # Clear graph\n",
    "  K.clear_session()\n",
    "  gc.collect()\n",
    "  \n",
    "  # Create filter for training data\n",
    "  train_filter = (sample_numbers != exclude_sample)\n",
    "\n",
    "  # Get indexes of all data\n",
    "  indexes = np.arange(len(sample_numbers))\n",
    "\n",
    "  # Create test data generator\n",
    "  test_generator = create_ds(indexes[~train_filter], BATCH_SIZE)\n",
    "\n",
    "  # Get saved model path\n",
    "  model_path = os.path.join(MODELS_PATH, f\"excluded_{exclude_sample}/\")\n",
    "\n",
    "  # Load model\n",
    "  classification_model = tf.keras.models.load_model(model_path)\n",
    "\n",
    "  # Get predictions\n",
    "  predictions[exclude_sample] = classification_model.predict(x=test_generator)\n",
    "  \n",
    "  # Get corresponding true labels\n",
    "  true_labels[exclude_sample] = (who_grades[~train_filter] > 2).astype(int)\n",
    "\n",
    "  # Clean model for next iteration\n",
    "  classification_model = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1f24c1",
   "metadata": {},
   "source": [
    "### ***Roc curve:***\n",
    "\n",
    "Next, let\"s plot LOOCV roc curve:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e714ba7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fpr, tpr, thresholds = metrics.roc_curve(\n",
    "  np.concatenate(list(true_labels.values())),\n",
    "  np.concatenate(list(predictions.values())))\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(fpr, tpr, \"b\", label = f\"AUC = {roc_auc:.3f}\")\n",
    "plt.legend(loc = \"lower right\")\n",
    "plt.plot([0, 1], [0, 1],\"r--\")\n",
    "plt.xlim([-0.05, 1.05])\n",
    "plt.ylim([-0.05, 1.05])\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.title(\"Receiver Operating Characteristic\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7b822b",
   "metadata": {},
   "source": [
    "### ***MSI parsers closing:***\n",
    "\n",
    "Next, let\"s close MSI parsers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c5bdfc8-4b31-4968-ae11-f271467cbec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Closing parsers\n",
    "for reader in parsers.values():\n",
    "  if reader.m:\n",
    "    reader.m.close()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5c73559c04fc51cf6f25e380b3ded5183311c605494f1c18f4c2cfbf285cb958"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('tf_gpu_jup')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
