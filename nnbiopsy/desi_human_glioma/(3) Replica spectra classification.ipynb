{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "856494bd-971b-4d53-92b6-a772f5934df5",
   "metadata": {},
   "source": [
    "# ***DESI Human Glioma Section Spectra Clinical State Classification***\n",
    "\n",
    "This notebook shows the process of section spectra clinical state classification of the DESI Human Glioma preprocessed dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39df2682-bf3f-4242-94ce-e6bf0b6dcf3c",
   "metadata": {},
   "source": [
    "### ***Import packages***\n",
    "\n",
    "Before we begin, let\"s import all the necessary packages for this notebook.\n",
    "First we add the directory which has our python files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e2f72dc-fcd1-47d5-8c2d-fea76cfeadc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"../..\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84395cb7-3bb2-46f7-9d9a-794a8eecdab4",
   "metadata": {},
   "source": [
    "Next we import all the necessary packages for this notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01b61342-ee57-4299-a9ce-a8993f8727fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from typing import Tuple\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras import callbacks\n",
    "from tensorflow.keras import backend as K\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage import (filters)\n",
    "from tqdm import tqdm\n",
    "from pyimzml.ImzMLParser import ImzMLParser, getionimage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87eebf16-66a7-4b26-8a4b-145d09cbe643",
   "metadata": {},
   "source": [
    "### ***Constants definitions***\n",
    "\n",
    "Next, let\"s define some constant variables for this notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37a05c91-3223-4591-92cc-1ae0d83e8604",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define folder that contains the dhg dataset and files\n",
    "DHG_PATH = \"C:/Users/Leor/Desktop/Thesis/DHG\"\n",
    "# Define folder that contains the preprocessed dhg dataset\n",
    "DHG_IN_PATH = f\"{DHG_PATH}/Preprocessed\"\n",
    "# Define file that contains dhg clinical state annotations\n",
    "CLINICAL_STATE_ANNOTATIONS_PATH = f\"{DHG_PATH}/Clinical_state_annotations.csv\"\n",
    "# Define folder to save classification models for later use\n",
    "MODELS_PATH = \"C:/Users/Leor/Desktop/Thesis/replica_classification_models\"\n",
    "# Classification model number of epochs\n",
    "EPHOCS = 50\n",
    "# Classification model batch size\n",
    "BATCH_SIZE = 256\n",
    "# Classification model learning rate\n",
    "LEARNING_RATE = 1e-3\n",
    "# MSI Spectra dimension\n",
    "SPECTRA_DIM = 92000\n",
    "# The MSI sample type for filtering\n",
    "SAMPLE_TYPE = \"r\"\n",
    "# Mz value to get in order to threshold for tissue\n",
    "TRESH_MZ = 750\n",
    "# Mz tolerance value to get in order to threshold for tissue\n",
    "TRESH_MZ_TOL = 150\n",
    "# Treshould standard deviation for Gaussian kernel\n",
    "TRESH_GAUSSIAN_SIGMA = 1.5 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c71392-9354-46f8-93d3-d1298fab3820",
   "metadata": {
    "tags": []
   },
   "source": [
    "### ***Reading MSI clinical state anotations***\n",
    "\n",
    "Next, lets read the clinical state anotations for each MSI:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33f91fd0-b6c6-4965-ad0c-180fbd1c74bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read clinical state annotations csv\n",
    "clinical_state_df = pd.read_csv(CLINICAL_STATE_ANNOTATIONS_PATH)\n",
    "\n",
    "# Filter by sample_type\n",
    "clinical_state_df = clinical_state_df[clinical_state_df[\"sample_type\"] ==\n",
    "                                      SAMPLE_TYPE]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b293bee-e70a-456b-8a75-c703e2ee0f15",
   "metadata": {},
   "source": [
    "### ***Get all tissue spectra from all MSI:***\n",
    "\n",
    "Next, let\"s get all informations except intensities (which need a lot of memory) for each tissue spectra from all MSI:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6aa78851-8993-4315-9e39-0095303a8735",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Spectra Loop: 100%|██████████| 4026/4026 [00:00<00:00, 96109.07it/s]\n",
      "Spectra Loop: 100%|██████████| 1856/1856 [00:00<00:00, 109072.71it/s]\n",
      "Spectra Loop: 100%|██████████| 2412/2412 [00:00<00:00, 114785.97it/s]\n",
      "Spectra Loop: 100%|██████████| 4875/4875 [00:00<00:00, 88872.41it/s]\n",
      "Spectra Loop: 100%|██████████| 4368/4368 [00:00<00:00, 91119.30it/s]\n",
      "Spectra Loop: 100%|██████████| 3074/3074 [00:00<00:00, 128242.96it/s]\n",
      "Spectra Loop: 100%|██████████| 3465/3465 [00:00<00:00, 123727.36it/s]\n",
      "Spectra Loop: 100%|██████████| 4422/4422 [00:00<00:00, 98529.60it/s]\n",
      "Spectra Loop: 100%|██████████| 4488/4488 [00:00<00:00, 99951.34it/s]\n",
      "Spectra Loop: 100%|██████████| 3111/3111 [00:00<00:00, 135624.98it/s]\n",
      "Spectra Loop: 100%|██████████| 5934/5934 [00:00<00:00, 123899.22it/s]\n",
      "Spectra Loop: 100%|██████████| 3658/3658 [00:00<00:00, 104654.47it/s]\n",
      "Spectra Loop: 100%|██████████| 4500/4500 [00:00<00:00, 112540.35it/s]\n",
      "Spectra Loop: 100%|██████████| 3835/3835 [00:00<00:00, 132455.70it/s]\n",
      "Spectra Loop: 100%|██████████| 4256/4256 [00:00<00:00, 118310.72it/s]\n",
      "Spectra Loop: 100%|██████████| 3477/3477 [00:00<00:00, 75741.62it/s]\n",
      "Spectra Loop: 100%|██████████| 5135/5135 [00:00<00:00, 95274.07it/s]\n",
      "Spectra Loop: 100%|██████████| 2562/2562 [00:00<00:00, 197598.60it/s]\n",
      "Spectra Loop: 100%|██████████| 3111/3111 [00:00<00:00, 148072.90it/s]\n",
      "Spectra Loop: 100%|██████████| 1496/1496 [00:00<00:00, 114660.46it/s]\n",
      "Spectra Loop: 100%|██████████| 1452/1452 [00:00<00:00, 145439.40it/s]\n",
      "Spectra Loop: 100%|██████████| 2184/2184 [00:00<00:00, 109107.76it/s]\n",
      "Spectra Loop: 100%|██████████| 4420/4420 [00:00<00:00, 88586.79it/s]\n",
      "Spectra Loop: 100%|██████████| 3192/3192 [00:00<00:00, 114170.63it/s]\n",
      "MSI Loop: 100%|██████████| 24/24 [02:52<00:00,  7.20s/it]\n"
     ]
    }
   ],
   "source": [
    "# Create lists to store each spectra's info\n",
    "file_names = []\n",
    "sample_numbers = []\n",
    "histologies = []\n",
    "who_grades = []\n",
    "x_coordinates = []\n",
    "y_coordinates = []\n",
    "idxs = []\n",
    "\n",
    "# Loop over each MSI\n",
    "for index, msi_row in tqdm(clinical_state_df.iterrows(),\n",
    "                           total=clinical_state_df.shape[0],\n",
    "                           desc=\"MSI Loop\"):\n",
    "  # Parse the MSI file\n",
    "  with ImzMLParser(os.path.join(DHG_IN_PATH,\n",
    "                                f\"{msi_row.file_name}.imzML\")) as reader:\n",
    "    # Get local TIC image of msi in mz region [600, 900]\n",
    "    local_tic_img = getionimage(reader, TRESH_MZ, tol=TRESH_MZ_TOL)\n",
    "\n",
    "    # Threshold image to separate tissue spectra from background\n",
    "    smooth = filters.gaussian(local_tic_img, sigma=TRESH_GAUSSIAN_SIGMA)\n",
    "    thresh_mean = filters.threshold_mean(smooth)\n",
    "    thresh_img = local_tic_img > thresh_mean\n",
    "\n",
    "    # Loop over each spectra\n",
    "    for idx, (x, y, z) in tqdm(enumerate(reader.coordinates),\n",
    "                               total=len(reader.coordinates),\n",
    "                               desc=\"Spectra Loop\"):\n",
    "      # Check if spectra is tissue\n",
    "      if thresh_img[y - 1, x - 1]:\n",
    "        # Keep sample file name of spectra\n",
    "        file_names.append(msi_row.file_name)\n",
    "        # Keep sample number of spectra\n",
    "        sample_numbers.append(msi_row.sample_number)\n",
    "        # Keep sample histology of spectra\n",
    "        histologies.append(msi_row.histology)\n",
    "        # Keep sample who grade of spectra\n",
    "        who_grades.append(msi_row.who_grade)\n",
    "        # Keep x coordinate of spectra\n",
    "        x_coordinates.append(x)\n",
    "        # Keep y coordinate of spectra\n",
    "        y_coordinates.append(y)\n",
    "        # Keep  of spectra\n",
    "        idxs.append(idx)\n",
    "\n",
    "# Convert to numpy array\n",
    "file_names = np.array(file_names)\n",
    "sample_numbers = np.array(sample_numbers)\n",
    "histologies = np.array(histologies)\n",
    "who_grades = np.array(who_grades)\n",
    "x_coordinates = np.array(x_coordinates)\n",
    "y_coordinates = np.array(y_coordinates)\n",
    "idxs = np.array(idxs)\n",
    "labels = (who_grades > 2).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b5a70b",
   "metadata": {},
   "source": [
    "### ***MSI parsers opening:***\n",
    "\n",
    "Next, let\"s create parser for each MSI in order to read spectra's for the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5b50d38-2238-455d-93a5-202c995c9f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening parsers\n",
    "parsers = {\n",
    "    file_name: ImzMLParser(os.path.join(DHG_IN_PATH, f\"{file_name}.imzML\"))\n",
    "    for file_name in clinical_state_df.file_name.unique()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10da83a3-78b5-48c9-a29f-8aa4ae06876a",
   "metadata": {},
   "source": [
    "### ***Dataset generator:***\n",
    "\n",
    "Next, let\"s create a dataset generator for the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d344c443-1d92-4e78-9330-90c25489e35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_index(index: tf.Tensor) -> Tuple[np.ndarray, int]:\n",
    "  \"\"\"Function to map index to model input (spectra) and output (label).\n",
    "\n",
    "  Args:\n",
    "      index (tf.Tensor): index to map to corresponding values.\n",
    "\n",
    "  Returns:\n",
    "      Tuple[np.ndarray, int]: input (spectra) and output (label).\n",
    "  \n",
    "  \"\"\"\n",
    "  # Decoding index from the EagerTensor object\n",
    "  index = index.numpy()\n",
    "  # Reading spectra from parser\n",
    "  file_name = file_names[index]\n",
    "  idx = idxs[index]\n",
    "  _, spectra = parsers[file_name].getspectrum(idx)\n",
    "  # Return spectra and label\n",
    "  return (spectra, labels[index])\n",
    "\n",
    "\n",
    "def _fixup_shape(x: tf.Tensor, y: tf.Tensor):\n",
    "  \"\"\" Function to Fix the implicit inferring of the shapes of the\n",
    "  output Tensors.\n",
    "\n",
    "  Args:\n",
    "      x (tf.Tensor): input (spectra)\n",
    "      y (tf.Tensor): output (label)\n",
    "\n",
    "  Returns:\n",
    "      Tuple[np.ndarray, np.ndarray]: input (spectra) and output (label) with\n",
    "        correct shape.\n",
    "  \n",
    "  \"\"\"\n",
    "  x.set_shape([SPECTRA_DIM])\n",
    "  y.set_shape([])\n",
    "  return x, y\n",
    "\n",
    "\n",
    "def create_ds(indexes: np.ndarray, batch_size: int) -> tf.data.Dataset:\n",
    "  \"\"\"Function to create a dataset for model\n",
    "\n",
    "  Args:\n",
    "      indexes (np.ndarray): indexes of thh dataset\n",
    "      batch_size (int): batch size\n",
    "\n",
    "  Returns:\n",
    "      tf.data.Dataset: dataset\n",
    "  \"\"\"\n",
    "  # Create dataset from indexes\n",
    "  ds = tf.data.Dataset.from_tensor_slices(indexes)\n",
    "  # Shuffle the data\n",
    "  ds = ds.shuffle(len(indexes))\n",
    "  # Map index to spectra\n",
    "  ds = ds.map(lambda i: tf.py_function(\n",
    "      func=map_index, inp=[i], Tout=[tf.float32, tf.float32]))\n",
    "  # Fix the implicit inferring of the shapes of the\n",
    "  # output Tensors\n",
    "  ds = ds.map(_fixup_shape)\n",
    "  # Batch the spectra's\n",
    "  ds = ds.batch(batch_size)\n",
    "  # Prefetch batchs to make sure that a batch is ready to\n",
    "  # be served at all time\n",
    "  ds = ds.prefetch(tf.data.AUTOTUNE)\n",
    "  return ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb64e399",
   "metadata": {},
   "source": [
    "### ***Classification model:***\n",
    "\n",
    "Next, let\"s create a classification dense neural network model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a06243a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model() -> tf.keras.Model:\n",
    "  \"\"\"Function to generate classification model.\n",
    "\n",
    "  Returns:\n",
    "      tf.keras.Model: classification model.\n",
    "  \n",
    "  \"\"\"\n",
    "  return tf.keras.Sequential(\n",
    "    [\n",
    "      layers.InputLayer(input_shape=(SPECTRA_DIM,)),\n",
    "      layers.Dense(512, activation='relu'),\n",
    "      layers.Dense(512, activation='relu'),\n",
    "      layers.Dense(256, activation='relu'),\n",
    "      layers.Dense(256, activation='relu'),\n",
    "      layers.Dense(128, activation='relu'),\n",
    "      layers.Dense(1, activation='sigmoid')\n",
    "    ]\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1fe68ee",
   "metadata": {},
   "source": [
    "### ***LOOCV Classification:***\n",
    "\n",
    "Next, let\"s apply classification using LOOCV for best evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c3a2175-3091-4045-ab39-5fb746b3f484",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/22 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "127/127 [==============================] - 39s 297ms/step - loss: 0.3502 - accuracy: 0.8339 - val_loss: 0.1959 - val_accuracy: 0.9339\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/replica_classification_models\\excluded_2\\assets\n",
      "Epoch 2/50\n",
      "127/127 [==============================] - 29s 230ms/step - loss: 0.0380 - accuracy: 0.9884 - val_loss: 0.0085 - val_accuracy: 0.9980\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/replica_classification_models\\excluded_2\\assets\n",
      "Epoch 3/50\n",
      "127/127 [==============================] - 30s 234ms/step - loss: 0.0047 - accuracy: 0.9988 - val_loss: 0.0075 - val_accuracy: 0.9980\n",
      "Epoch 4/50\n",
      "127/127 [==============================] - 30s 233ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.0093 - val_accuracy: 0.9972\n",
      "Epoch 5/50\n",
      "127/127 [==============================] - 30s 240ms/step - loss: 0.0011 - accuracy: 0.9999 - val_loss: 0.0057 - val_accuracy: 0.9990\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/replica_classification_models\\excluded_2\\assets\n",
      "Epoch 6/50\n",
      "127/127 [==============================] - 29s 229ms/step - loss: 7.5194e-04 - accuracy: 0.9999 - val_loss: 0.0057 - val_accuracy: 0.9989\n",
      "Epoch 7/50\n",
      "127/127 [==============================] - 30s 233ms/step - loss: 6.9176e-04 - accuracy: 0.9999 - val_loss: 0.0059 - val_accuracy: 0.9985\n",
      "Epoch 8/50\n",
      "127/127 [==============================] - 30s 234ms/step - loss: 6.6934e-04 - accuracy: 0.9999 - val_loss: 0.0058 - val_accuracy: 0.9989\n",
      "Epoch 9/50\n",
      "127/127 [==============================] - 31s 242ms/step - loss: 6.4933e-04 - accuracy: 0.9999 - val_loss: 0.0058 - val_accuracy: 0.9989\n",
      "Epoch 10/50\n",
      "127/127 [==============================] - 31s 242ms/step - loss: 6.4008e-04 - accuracy: 0.9999 - val_loss: 0.0058 - val_accuracy: 0.9989\n",
      "Epoch 00010: early stopping\n",
      "11/11 [==============================] - 3s 282ms/step - loss: 13.0594 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 1/22 [05:20<1:52:13, 320.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "126/126 [==============================] - 30s 234ms/step - loss: 0.4064 - accuracy: 0.7865 - val_loss: 0.1856 - val_accuracy: 0.9407\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/replica_classification_models\\excluded_3\\assets\n",
      "Epoch 2/50\n",
      "126/126 [==============================] - 29s 233ms/step - loss: 0.1339 - accuracy: 0.9511 - val_loss: 0.0242 - val_accuracy: 0.9922\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/replica_classification_models\\excluded_3\\assets\n",
      "Epoch 3/50\n",
      "126/126 [==============================] - 30s 238ms/step - loss: 0.0085 - accuracy: 0.9971 - val_loss: 0.0107 - val_accuracy: 0.9970\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/replica_classification_models\\excluded_3\\assets\n",
      "Epoch 4/50\n",
      "126/126 [==============================] - 30s 238ms/step - loss: 0.1753 - accuracy: 0.9648 - val_loss: 0.0064 - val_accuracy: 0.9991\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/replica_classification_models\\excluded_3\\assets\n",
      "Epoch 5/50\n",
      "126/126 [==============================] - 29s 228ms/step - loss: 0.0011 - accuracy: 0.9999 - val_loss: 0.0043 - val_accuracy: 0.9993\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/replica_classification_models\\excluded_3\\assets\n",
      "Epoch 6/50\n",
      "126/126 [==============================] - 30s 237ms/step - loss: 2.5260e-04 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 0.9991\n",
      "Epoch 7/50\n",
      "126/126 [==============================] - 30s 236ms/step - loss: 1.2777e-04 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9991\n",
      "Epoch 8/50\n",
      "126/126 [==============================] - 30s 242ms/step - loss: 5.6865e-05 - accuracy: 1.0000 - val_loss: 0.0047 - val_accuracy: 0.9993\n",
      "Epoch 9/50\n",
      "126/126 [==============================] - 30s 239ms/step - loss: 3.4302e-05 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 0.9993\n",
      "Epoch 10/50\n",
      "126/126 [==============================] - 31s 248ms/step - loss: 2.1571e-05 - accuracy: 1.0000 - val_loss: 0.0050 - val_accuracy: 0.9993\n",
      "Epoch 00010: early stopping\n",
      "12/12 [==============================] - 2s 155ms/step - loss: 3.0949 - accuracy: 0.1847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 2/22 [10:33<1:45:15, 315.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "133/133 [==============================] - 33s 249ms/step - loss: 0.4184 - accuracy: 0.7787 - val_loss: 0.1730 - val_accuracy: 0.9430\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/replica_classification_models\\excluded_4\\assets\n",
      "Epoch 2/50\n",
      "133/133 [==============================] - 31s 234ms/step - loss: 0.0895 - accuracy: 0.9630 - val_loss: 0.0317 - val_accuracy: 0.9948\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/replica_classification_models\\excluded_4\\assets\n",
      "Epoch 3/50\n",
      "133/133 [==============================] - 32s 238ms/step - loss: 0.0051 - accuracy: 0.9991 - val_loss: 0.0037 - val_accuracy: 0.9991\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/replica_classification_models\\excluded_4\\assets\n",
      "Epoch 4/50\n",
      "133/133 [==============================] - 32s 242ms/step - loss: 3.6178e-04 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 0.9994\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/replica_classification_models\\excluded_4\\assets\n",
      "Epoch 5/50\n",
      "133/133 [==============================] - 31s 232ms/step - loss: 4.3944e-05 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 0.9993\n",
      "Epoch 6/50\n",
      "133/133 [==============================] - 32s 238ms/step - loss: 2.4042e-05 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 0.9994\n",
      "Epoch 7/50\n",
      "133/133 [==============================] - 31s 232ms/step - loss: 1.4687e-05 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 0.9994\n",
      "Epoch 8/50\n",
      "133/133 [==============================] - 31s 229ms/step - loss: 1.0040e-05 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 0.9994\n",
      "Epoch 9/50\n",
      "133/133 [==============================] - 30s 227ms/step - loss: 7.1620e-06 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 0.9993\n",
      "Epoch 00009: early stopping\n",
      "3/3 [==============================] - 1s 206ms/step - loss: 4.4371e-08 - accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▎        | 3/22 [15:25<1:36:41, 305.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "132/132 [==============================] - 31s 234ms/step - loss: 0.4411 - accuracy: 0.7646 - val_loss: 0.1794 - val_accuracy: 0.9420\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/replica_classification_models\\excluded_5\\assets\n",
      "Epoch 2/50\n",
      "132/132 [==============================] - 30s 228ms/step - loss: 0.0938 - accuracy: 0.9659 - val_loss: 0.0228 - val_accuracy: 0.9925\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/replica_classification_models\\excluded_5\\assets\n",
      "Epoch 3/50\n",
      "132/132 [==============================] - 31s 237ms/step - loss: 0.0036 - accuracy: 0.9990 - val_loss: 0.0046 - val_accuracy: 0.9987\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/replica_classification_models\\excluded_5\\assets\n",
      "Epoch 4/50\n",
      "132/132 [==============================] - 30s 227ms/step - loss: 2.1611e-04 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 0.9994\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/replica_classification_models\\excluded_5\\assets\n",
      "Epoch 5/50\n",
      "132/132 [==============================] - 30s 231ms/step - loss: 3.8723e-05 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 0.9994\n",
      "Epoch 6/50\n",
      "132/132 [==============================] - 33s 249ms/step - loss: 1.7897e-05 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 0.9994\n",
      "Epoch 7/50\n",
      "132/132 [==============================] - 30s 226ms/step - loss: 1.1737e-05 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 0.9994\n",
      "Epoch 8/50\n",
      "132/132 [==============================] - 34s 258ms/step - loss: 8.3341e-06 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 0.9994\n",
      "Epoch 9/50\n",
      "132/132 [==============================] - 32s 244ms/step - loss: 6.4261e-06 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 0.9994\n",
      "Epoch 00009: early stopping\n",
      "5/5 [==============================] - 1s 189ms/step - loss: 9.4083e-09 - accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 4/22 [20:18<1:30:06, 300.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "131/131 [==============================] - 31s 233ms/step - loss: 0.4681 - accuracy: 0.7463 - val_loss: 0.1922 - val_accuracy: 0.9386\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/replica_classification_models\\excluded_6\\assets\n",
      "Epoch 2/50\n",
      "131/131 [==============================] - 31s 234ms/step - loss: 0.1388 - accuracy: 0.9487 - val_loss: 0.0448 - val_accuracy: 0.9912\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/replica_classification_models\\excluded_6\\assets\n",
      "Epoch 3/50\n",
      "131/131 [==============================] - 30s 225ms/step - loss: 0.0131 - accuracy: 0.9961 - val_loss: 0.0053 - val_accuracy: 0.9990\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/replica_classification_models\\excluded_6\\assets\n",
      "Epoch 4/50\n",
      "131/131 [==============================] - 31s 233ms/step - loss: 4.6251e-04 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 0.9992\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/replica_classification_models\\excluded_6\\assets\n",
      "Epoch 5/50\n",
      "131/131 [==============================] - 29s 225ms/step - loss: 8.3272e-05 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 0.9993\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/replica_classification_models\\excluded_6\\assets\n",
      "Epoch 6/50\n",
      "131/131 [==============================] - 31s 236ms/step - loss: 2.3825e-05 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 0.9993\n",
      "Epoch 7/50\n",
      "131/131 [==============================] - 30s 227ms/step - loss: 1.1152e-05 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 0.9993\n",
      "Epoch 8/50\n",
      "131/131 [==============================] - 30s 228ms/step - loss: 6.2920e-06 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 0.9993\n",
      "Epoch 9/50\n",
      "131/131 [==============================] - 31s 235ms/step - loss: 4.0381e-06 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 0.9992\n",
      "Epoch 00009: early stopping\n",
      "6/6 [==============================] - 1s 167ms/step - loss: 1.0192e-12 - accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 5/22 [25:03<1:23:32, 294.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "132/132 [==============================] - 31s 231ms/step - loss: 0.4359 - accuracy: 0.7757 - val_loss: 0.1820 - val_accuracy: 0.9418\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/replica_classification_models\\excluded_7\\assets\n",
      "Epoch 2/50\n",
      "132/132 [==============================] - 31s 232ms/step - loss: 0.1552 - accuracy: 0.9459 - val_loss: 0.0960 - val_accuracy: 0.9419\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/replica_classification_models\\excluded_7\\assets\n",
      "Epoch 3/50\n",
      "132/132 [==============================] - 29s 222ms/step - loss: 0.0377 - accuracy: 0.9810 - val_loss: 0.0078 - val_accuracy: 0.9983\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/replica_classification_models\\excluded_7\\assets\n",
      "Epoch 4/50\n",
      "132/132 [==============================] - 31s 234ms/step - loss: 0.0022 - accuracy: 0.9995 - val_loss: 0.0035 - val_accuracy: 0.9994\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/replica_classification_models\\excluded_7\\assets\n",
      "Epoch 5/50\n",
      "132/132 [==============================] - 31s 235ms/step - loss: 1.5164e-04 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 0.9995\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/replica_classification_models\\excluded_7\\assets\n",
      "Epoch 6/50\n",
      "132/132 [==============================] - 32s 243ms/step - loss: 5.2931e-05 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 0.9993\n",
      "Epoch 7/50\n",
      "132/132 [==============================] - 31s 236ms/step - loss: 1.5412e-05 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 0.9993\n",
      "Epoch 8/50\n",
      "132/132 [==============================] - 30s 230ms/step - loss: 7.7484e-06 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 0.9994\n",
      "Epoch 9/50\n",
      "132/132 [==============================] - 29s 219ms/step - loss: 4.5379e-06 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 0.9993\n",
      "Epoch 10/50\n",
      "132/132 [==============================] - 31s 234ms/step - loss: 2.9667e-06 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 0.9994\n",
      "Epoch 00010: early stopping\n",
      "5/5 [==============================] - 1s 163ms/step - loss: 8.4818e-04 - accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 6/22 [30:22<1:20:48, 303.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "127/127 [==============================] - 30s 232ms/step - loss: 0.4232 - accuracy: 0.7686 - val_loss: 0.1827 - val_accuracy: 0.9397\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/replica_classification_models\\excluded_8\\assets\n",
      "Epoch 2/50\n",
      "127/127 [==============================] - 31s 244ms/step - loss: 0.0924 - accuracy: 0.9626 - val_loss: 0.1938 - val_accuracy: 0.9314\n",
      "Epoch 3/50\n",
      "127/127 [==============================] - 30s 240ms/step - loss: 0.0117 - accuracy: 0.9964 - val_loss: 0.0029 - val_accuracy: 0.9994\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/replica_classification_models\\excluded_8\\assets\n",
      "Epoch 4/50\n",
      "127/127 [==============================] - 30s 236ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 0.0025 - val_accuracy: 0.9994\n",
      "Epoch 5/50\n",
      "127/127 [==============================] - 30s 238ms/step - loss: 1.2655e-04 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 0.9994\n",
      "Epoch 6/50\n",
      "127/127 [==============================] - 30s 237ms/step - loss: 4.9526e-05 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 0.9995\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/replica_classification_models\\excluded_8\\assets\n",
      "Epoch 7/50\n",
      "127/127 [==============================] - 29s 230ms/step - loss: 3.0671e-05 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 0.9995\n",
      "Epoch 8/50\n",
      "127/127 [==============================] - 31s 244ms/step - loss: 2.1880e-05 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 0.9994\n",
      "Epoch 9/50\n",
      "127/127 [==============================] - 30s 237ms/step - loss: 1.6051e-05 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 0.9994\n",
      "Epoch 10/50\n",
      "127/127 [==============================] - 31s 244ms/step - loss: 1.2427e-05 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 0.9994\n",
      "Epoch 00010: early stopping\n",
      "12/12 [==============================] - 2s 156ms/step - loss: 0.6318 - accuracy: 0.7247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 7/22 [35:34<1:16:29, 305.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "131/131 [==============================] - 32s 242ms/step - loss: 0.4419 - accuracy: 0.7616 - val_loss: 0.1813 - val_accuracy: 0.9408\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/replica_classification_models\\excluded_9\\assets\n",
      "Epoch 2/50\n",
      "131/131 [==============================] - 31s 236ms/step - loss: 0.0698 - accuracy: 0.9736 - val_loss: 0.0110 - val_accuracy: 0.9982\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/replica_classification_models\\excluded_9\\assets\n",
      "Epoch 3/50\n",
      "131/131 [==============================] - 32s 242ms/step - loss: 0.0033 - accuracy: 0.9993 - val_loss: 0.0179 - val_accuracy: 0.9935\n",
      "Epoch 4/50\n",
      "131/131 [==============================] - 31s 239ms/step - loss: 9.1209e-04 - accuracy: 0.9999 - val_loss: 0.0021 - val_accuracy: 0.9993\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/replica_classification_models\\excluded_9\\assets\n",
      "Epoch 5/50\n",
      "131/131 [==============================] - 32s 241ms/step - loss: 3.2790e-04 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 0.9994\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/replica_classification_models\\excluded_9\\assets\n",
      "Epoch 6/50\n",
      "131/131 [==============================] - 32s 243ms/step - loss: 3.3363e-04 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 0.9993\n",
      "Epoch 7/50\n",
      "131/131 [==============================] - 31s 240ms/step - loss: 3.0586e-04 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 0.9994\n",
      "Epoch 8/50\n",
      "131/131 [==============================] - 30s 232ms/step - loss: 2.8533e-04 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 0.9994\n",
      "Epoch 9/50\n",
      "131/131 [==============================] - 29s 225ms/step - loss: 3.2841e-04 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 0.9994\n",
      "Epoch 10/50\n",
      "131/131 [==============================] - 32s 242ms/step - loss: 2.7022e-04 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 0.9994\n",
      "Epoch 00010: early stopping\n",
      "6/6 [==============================] - 1s 203ms/step - loss: 8.7586e-10 - accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▋      | 8/22 [40:58<1:12:42, 311.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "129/129 [==============================] - 30s 228ms/step - loss: 0.4209 - accuracy: 0.7839 - val_loss: 0.1819 - val_accuracy: 0.9423\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/replica_classification_models\\excluded_10\\assets\n",
      "Epoch 2/50\n",
      "129/129 [==============================] - 31s 236ms/step - loss: 0.1030 - accuracy: 0.9618 - val_loss: 0.0127 - val_accuracy: 0.9972\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/replica_classification_models\\excluded_10\\assets\n",
      "Epoch 3/50\n",
      "129/129 [==============================] - 31s 239ms/step - loss: 0.1321 - accuracy: 0.9654 - val_loss: 0.1445 - val_accuracy: 0.9423\n",
      "Epoch 4/50\n",
      "129/129 [==============================] - 30s 233ms/step - loss: 0.0246 - accuracy: 0.9926 - val_loss: 0.0047 - val_accuracy: 0.9993\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/replica_classification_models\\excluded_10\\assets\n",
      "Epoch 5/50\n",
      "129/129 [==============================] - 30s 233ms/step - loss: 0.0014 - accuracy: 0.9999 - val_loss: 0.0029 - val_accuracy: 0.9993\n",
      "Epoch 6/50\n",
      "129/129 [==============================] - 29s 227ms/step - loss: 4.6290e-04 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 0.9993\n",
      "Epoch 7/50\n",
      "129/129 [==============================] - 31s 240ms/step - loss: 2.3043e-04 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 0.9993\n",
      "Epoch 8/50\n",
      "129/129 [==============================] - 33s 257ms/step - loss: 1.2037e-04 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 0.9993\n",
      "Epoch 9/50\n",
      "129/129 [==============================] - 31s 238ms/step - loss: 7.5211e-05 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 0.9993\n",
      "Epoch 10/50\n",
      "129/129 [==============================] - 31s 239ms/step - loss: 4.8309e-05 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 0.9993\n",
      "Epoch 11/50\n",
      "129/129 [==============================] - 30s 235ms/step - loss: 2.2303e-05 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 0.9993\n",
      "Epoch 12/50\n",
      "129/129 [==============================] - 31s 242ms/step - loss: 1.2844e-05 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 0.9993\n",
      "Epoch 13/50\n",
      "129/129 [==============================] - 31s 243ms/step - loss: 8.2521e-06 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 0.9993\n",
      "Epoch 14/50\n",
      "129/129 [==============================] - 32s 248ms/step - loss: 5.5241e-06 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 0.9993\n",
      "Epoch 15/50\n",
      "129/129 [==============================] - 30s 235ms/step - loss: 4.1406e-06 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 0.9993\n",
      "Epoch 00015: early stopping\n",
      "9/9 [==============================] - 2s 186ms/step - loss: 2.5156e-07 - accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 9/22 [48:49<1:18:20, 361.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "133/133 [==============================] - 32s 241ms/step - loss: 0.3965 - accuracy: 0.7963 - val_loss: 0.1790 - val_accuracy: 0.9432\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/replica_classification_models\\excluded_11\\assets\n",
      "Epoch 2/50\n",
      "133/133 [==============================] - 32s 237ms/step - loss: 0.1000 - accuracy: 0.9611 - val_loss: 0.0128 - val_accuracy: 0.9965\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/replica_classification_models\\excluded_11\\assets\n",
      "Epoch 3/50\n",
      "133/133 [==============================] - 33s 247ms/step - loss: 0.1416 - accuracy: 0.9721 - val_loss: 0.0127 - val_accuracy: 0.9983\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/replica_classification_models\\excluded_11\\assets\n",
      "Epoch 4/50\n",
      "133/133 [==============================] - 35s 260ms/step - loss: 0.0045 - accuracy: 0.9994 - val_loss: 0.0055 - val_accuracy: 0.9986\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/replica_classification_models\\excluded_11\\assets\n",
      "Epoch 5/50\n",
      "133/133 [==============================] - 32s 241ms/step - loss: 0.0011 - accuracy: 0.9999 - val_loss: 0.0047 - val_accuracy: 0.9988\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/replica_classification_models\\excluded_11\\assets\n",
      "Epoch 6/50\n",
      "133/133 [==============================] - 33s 246ms/step - loss: 5.3339e-04 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9988\n",
      "Epoch 7/50\n",
      "133/133 [==============================] - 32s 241ms/step - loss: 1.3354e-04 - accuracy: 1.0000 - val_loss: 0.0050 - val_accuracy: 0.9988\n",
      "Epoch 8/50\n",
      "133/133 [==============================] - 33s 248ms/step - loss: 5.8568e-05 - accuracy: 1.0000 - val_loss: 0.0055 - val_accuracy: 0.9989\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/replica_classification_models\\excluded_11\\assets\n",
      "Epoch 9/50\n",
      "133/133 [==============================] - 30s 228ms/step - loss: 2.5646e-05 - accuracy: 1.0000 - val_loss: 0.0057 - val_accuracy: 0.9988\n",
      "Epoch 10/50\n",
      "133/133 [==============================] - 30s 228ms/step - loss: 1.3381e-05 - accuracy: 1.0000 - val_loss: 0.0062 - val_accuracy: 0.9988\n",
      "Epoch 00010: early stopping\n",
      "4/4 [==============================] - 1s 188ms/step - loss: 3.6919 - accuracy: 0.5332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 10/22 [54:26<1:10:45, 353.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "132/132 [==============================] - 31s 233ms/step - loss: 0.4364 - accuracy: 0.7660 - val_loss: 0.2042 - val_accuracy: 0.9294\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/replica_classification_models\\excluded_12\\assets\n",
      "Epoch 2/50\n",
      "132/132 [==============================] - 30s 227ms/step - loss: 0.1351 - accuracy: 0.9511 - val_loss: 0.0304 - val_accuracy: 0.9908\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/replica_classification_models\\excluded_12\\assets\n",
      "Epoch 3/50\n",
      "132/132 [==============================] - 33s 251ms/step - loss: 0.0073 - accuracy: 0.9975 - val_loss: 0.0048 - val_accuracy: 0.9989\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/replica_classification_models\\excluded_12\\assets\n",
      "Epoch 4/50\n",
      "132/132 [==============================] - 32s 242ms/step - loss: 2.9708e-04 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 0.9990\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/replica_classification_models\\excluded_12\\assets\n",
      "Epoch 5/50\n",
      "132/132 [==============================] - 32s 243ms/step - loss: 8.6758e-05 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 0.9992\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/replica_classification_models\\excluded_12\\assets\n",
      "Epoch 6/50\n",
      "132/132 [==============================] - 33s 246ms/step - loss: 3.2835e-05 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9992\n",
      "Epoch 7/50\n",
      "132/132 [==============================] - 33s 247ms/step - loss: 2.2307e-05 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9992\n",
      "Epoch 8/50\n",
      "132/132 [==============================] - 30s 231ms/step - loss: 1.6584e-05 - accuracy: 1.0000 - val_loss: 0.0047 - val_accuracy: 0.9990\n",
      "Epoch 9/50\n",
      "132/132 [==============================] - 32s 239ms/step - loss: 1.2742e-05 - accuracy: 1.0000 - val_loss: 0.0047 - val_accuracy: 0.9992\n",
      "Epoch 00009: early stopping\n",
      "5/5 [==============================] - 1s 160ms/step - loss: 1.1396e-17 - accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 11/22 [59:23<1:01:42, 336.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "127/127 [==============================] - 31s 241ms/step - loss: 0.4334 - accuracy: 0.7673 - val_loss: 0.1804 - val_accuracy: 0.9421\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/replica_classification_models\\excluded_13\\assets\n",
      "Epoch 2/50\n",
      "127/127 [==============================] - 31s 243ms/step - loss: 0.1459 - accuracy: 0.9552 - val_loss: 0.3648 - val_accuracy: 0.8254\n",
      "Epoch 3/50\n",
      "127/127 [==============================] - 32s 248ms/step - loss: 0.2179 - accuracy: 0.9247 - val_loss: 0.0141 - val_accuracy: 0.9975\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/replica_classification_models\\excluded_13\\assets\n",
      "Epoch 4/50\n",
      "127/127 [==============================] - 30s 231ms/step - loss: 0.0057 - accuracy: 0.9989 - val_loss: 0.0149 - val_accuracy: 0.9963\n",
      "Epoch 5/50\n",
      "127/127 [==============================] - 31s 245ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.0044 - val_accuracy: 0.9989\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/replica_classification_models\\excluded_13\\assets\n",
      "Epoch 6/50\n",
      "127/127 [==============================] - 32s 252ms/step - loss: 5.9549e-04 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 0.9989\n",
      "Epoch 7/50\n",
      "127/127 [==============================] - 31s 243ms/step - loss: 4.2499e-04 - accuracy: 1.0000 - val_loss: 0.0047 - val_accuracy: 0.9990\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/replica_classification_models\\excluded_13\\assets\n",
      "Epoch 8/50\n",
      "127/127 [==============================] - 30s 236ms/step - loss: 3.5684e-04 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 0.9989\n",
      "Epoch 9/50\n",
      "127/127 [==============================] - 30s 239ms/step - loss: 3.2376e-04 - accuracy: 1.0000 - val_loss: 0.0047 - val_accuracy: 0.9990\n",
      "Epoch 10/50\n",
      "127/127 [==============================] - 30s 233ms/step - loss: 3.0271e-04 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 0.9990\n",
      "Epoch 00010: early stopping\n",
      "12/12 [==============================] - 3s 200ms/step - loss: 0.2686 - accuracy: 0.9405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 12/22 [1:04:43<55:13, 331.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "128/128 [==============================] - 32s 250ms/step - loss: 0.4572 - accuracy: 0.7475 - val_loss: 0.1856 - val_accuracy: 0.9398\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/replica_classification_models\\excluded_14\\assets\n",
      "Epoch 2/50\n",
      "128/128 [==============================] - 32s 253ms/step - loss: 0.1162 - accuracy: 0.9571 - val_loss: 0.0238 - val_accuracy: 0.9925\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/replica_classification_models\\excluded_14\\assets\n",
      "Epoch 3/50\n",
      "128/128 [==============================] - 32s 248ms/step - loss: 0.0435 - accuracy: 0.9880 - val_loss: 0.0082 - val_accuracy: 0.9980\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/replica_classification_models\\excluded_14\\assets\n",
      "Epoch 4/50\n",
      "128/128 [==============================] - 31s 244ms/step - loss: 0.0025 - accuracy: 0.9996 - val_loss: 0.0083 - val_accuracy: 0.9980\n",
      "Epoch 5/50\n",
      "128/128 [==============================] - 32s 249ms/step - loss: 6.1549e-04 - accuracy: 0.9999 - val_loss: 0.0032 - val_accuracy: 0.9994\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/replica_classification_models\\excluded_14\\assets\n",
      "Epoch 6/50\n",
      "128/128 [==============================] - 31s 244ms/step - loss: 1.6788e-04 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 0.9994\n",
      "Epoch 7/50\n",
      "128/128 [==============================] - 31s 239ms/step - loss: 5.6931e-05 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 0.9995\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/replica_classification_models\\excluded_14\\assets\n",
      "Epoch 8/50\n",
      "128/128 [==============================] - 32s 247ms/step - loss: 2.7633e-05 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 0.9995\n",
      "Epoch 9/50\n",
      "128/128 [==============================] - 31s 244ms/step - loss: 1.1629e-05 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 0.9994\n",
      "Epoch 10/50\n",
      "128/128 [==============================] - 32s 247ms/step - loss: 7.6044e-06 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 0.9995\n",
      "Epoch 11/50\n",
      "128/128 [==============================] - 30s 235ms/step - loss: 4.8285e-06 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 0.9995\n",
      "Epoch 00011: early stopping\n",
      "10/10 [==============================] - 2s 197ms/step - loss: 0.5345 - accuracy: 0.8607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 13/22 [1:10:42<50:59, 339.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "131/131 [==============================] - 32s 239ms/step - loss: 0.4350 - accuracy: 0.7666 - val_loss: 0.1757 - val_accuracy: 0.9454\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/replica_classification_models\\excluded_15\\assets\n",
      "Epoch 2/50\n",
      "131/131 [==============================] - 30s 226ms/step - loss: 0.1682 - accuracy: 0.9458 - val_loss: 0.1490 - val_accuracy: 0.9462\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/replica_classification_models\\excluded_15\\assets\n",
      "Epoch 3/50\n",
      "131/131 [==============================] - 31s 235ms/step - loss: 0.0513 - accuracy: 0.9756 - val_loss: 0.0056 - val_accuracy: 0.9984\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/replica_classification_models\\excluded_15\\assets\n",
      "Epoch 4/50\n",
      "131/131 [==============================] - 31s 237ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.0031 - val_accuracy: 0.9987\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/replica_classification_models\\excluded_15\\assets\n",
      "Epoch 5/50\n",
      "131/131 [==============================] - 31s 233ms/step - loss: 3.0345e-04 - accuracy: 0.9999 - val_loss: 0.0023 - val_accuracy: 0.9992\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/replica_classification_models\\excluded_15\\assets\n",
      "Epoch 6/50\n",
      "131/131 [==============================] - 31s 237ms/step - loss: 4.5010e-05 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 0.9990\n",
      "Epoch 7/50\n",
      "131/131 [==============================] - 31s 236ms/step - loss: 2.6126e-05 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 0.9992\n",
      "Epoch 8/50\n",
      "131/131 [==============================] - 32s 243ms/step - loss: 1.2740e-05 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 0.9993\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/replica_classification_models\\excluded_15\\assets\n",
      "Epoch 9/50\n",
      "131/131 [==============================] - 31s 237ms/step - loss: 6.2112e-06 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 0.9993\n",
      "Epoch 10/50\n",
      "131/131 [==============================] - 32s 243ms/step - loss: 3.8693e-06 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 0.9993\n",
      "Epoch 11/50\n",
      "131/131 [==============================] - 31s 235ms/step - loss: 2.6363e-06 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 0.9993\n",
      "Epoch 00011: early stopping\n",
      "6/6 [==============================] - 1s 134ms/step - loss: 4.7321 - accuracy: 0.1583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▎   | 14/22 [1:16:38<45:58, 344.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "131/131 [==============================] - 31s 238ms/step - loss: 0.4282 - accuracy: 0.7759 - val_loss: 0.1761 - val_accuracy: 0.9408\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/replica_classification_models\\excluded_16\\assets\n",
      "Epoch 2/50\n",
      "131/131 [==============================] - 31s 235ms/step - loss: 0.0843 - accuracy: 0.9679 - val_loss: 0.0091 - val_accuracy: 0.9980\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/replica_classification_models\\excluded_16\\assets\n",
      "Epoch 3/50\n",
      "131/131 [==============================] - 31s 238ms/step - loss: 0.0027 - accuracy: 0.9993 - val_loss: 0.0080 - val_accuracy: 0.9983\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/replica_classification_models\\excluded_16\\assets\n",
      "Epoch 4/50\n",
      "131/131 [==============================] - 32s 244ms/step - loss: 0.0023 - accuracy: 0.9998 - val_loss: 0.0055 - val_accuracy: 0.9992\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/replica_classification_models\\excluded_16\\assets\n",
      "Epoch 5/50\n",
      "131/131 [==============================] - 32s 240ms/step - loss: 8.9469e-05 - accuracy: 1.0000 - val_loss: 0.0051 - val_accuracy: 0.9993\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/replica_classification_models\\excluded_16\\assets\n",
      "Epoch 6/50\n",
      "131/131 [==============================] - 33s 248ms/step - loss: 3.1441e-05 - accuracy: 1.0000 - val_loss: 0.0051 - val_accuracy: 0.9995\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/replica_classification_models\\excluded_16\\assets\n",
      "Epoch 7/50\n",
      "131/131 [==============================] - 33s 251ms/step - loss: 1.8824e-05 - accuracy: 1.0000 - val_loss: 0.0052 - val_accuracy: 0.9995\n",
      "Epoch 8/50\n",
      "131/131 [==============================] - 31s 234ms/step - loss: 1.2082e-05 - accuracy: 1.0000 - val_loss: 0.0053 - val_accuracy: 0.9995\n",
      "Epoch 9/50\n",
      "131/131 [==============================] - 30s 229ms/step - loss: 7.2997e-06 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 0.9995\n",
      "Epoch 10/50\n",
      "131/131 [==============================] - 33s 253ms/step - loss: 4.3481e-06 - accuracy: 1.0000 - val_loss: 0.0059 - val_accuracy: 0.9993\n",
      "Epoch 00010: early stopping\n",
      "6/6 [==============================] - 2s 230ms/step - loss: 14.9398 - accuracy: 0.0159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 15/22 [1:22:10<39:45, 340.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "121/121 [==============================] - 29s 240ms/step - loss: 0.4547 - accuracy: 0.7648 - val_loss: 0.1829 - val_accuracy: 0.9354\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/replica_classification_models\\excluded_18\\assets\n",
      "Epoch 2/50\n",
      "121/121 [==============================] - 29s 235ms/step - loss: 0.1333 - accuracy: 0.9429 - val_loss: 0.0573 - val_accuracy: 0.9904\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/replica_classification_models\\excluded_18\\assets\n",
      "Epoch 3/50\n",
      "121/121 [==============================] - 29s 239ms/step - loss: 0.2072 - accuracy: 0.9565 - val_loss: 0.0262 - val_accuracy: 0.9945\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/replica_classification_models\\excluded_18\\assets\n",
      "Epoch 4/50\n",
      "121/121 [==============================] - 29s 240ms/step - loss: 0.0097 - accuracy: 0.9990 - val_loss: 0.0086 - val_accuracy: 0.9988\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/replica_classification_models\\excluded_18\\assets\n",
      "Epoch 5/50\n",
      "121/121 [==============================] - 29s 243ms/step - loss: 0.0036 - accuracy: 0.9997 - val_loss: 0.0054 - val_accuracy: 0.9988\n",
      "Epoch 6/50\n",
      "121/121 [==============================] - 28s 234ms/step - loss: 0.0018 - accuracy: 0.9999 - val_loss: 0.0048 - val_accuracy: 0.9990\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/replica_classification_models\\excluded_18\\assets\n",
      "Epoch 7/50\n",
      "121/121 [==============================] - 29s 236ms/step - loss: 0.0012 - accuracy: 0.9999 - val_loss: 0.0040 - val_accuracy: 0.9990\n",
      "Epoch 8/50\n",
      "121/121 [==============================] - 29s 243ms/step - loss: 8.0505e-04 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 0.9990\n",
      "Epoch 9/50\n",
      "121/121 [==============================] - 30s 244ms/step - loss: 5.9911e-04 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 0.9990\n",
      "Epoch 10/50\n",
      "121/121 [==============================] - 30s 248ms/step - loss: 5.1968e-04 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 0.9990\n",
      "Epoch 11/50\n",
      "121/121 [==============================] - 28s 230ms/step - loss: 4.6976e-04 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 0.9990\n",
      "Epoch 12/50\n",
      "121/121 [==============================] - 30s 249ms/step - loss: 4.3929e-04 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 0.9990\n",
      "Epoch 13/50\n",
      "121/121 [==============================] - 31s 252ms/step - loss: 4.1680e-04 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 0.9990\n",
      "Epoch 14/50\n",
      "121/121 [==============================] - 30s 244ms/step - loss: 3.9834e-04 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 0.9990\n",
      "Epoch 15/50\n",
      "121/121 [==============================] - 30s 248ms/step - loss: 3.8271e-04 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 0.9990\n",
      "Epoch 00015: early stopping\n",
      "19/19 [==============================] - 3s 159ms/step - loss: 0.2983 - accuracy: 0.9466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 16/22 [1:29:43<37:28, 374.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "132/132 [==============================] - 34s 252ms/step - loss: 0.4101 - accuracy: 0.7931 - val_loss: 0.1840 - val_accuracy: 0.9399\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/replica_classification_models\\excluded_19\\assets\n",
      "Epoch 2/50\n",
      "132/132 [==============================] - 33s 248ms/step - loss: 0.1644 - accuracy: 0.9470 - val_loss: 0.1660 - val_accuracy: 0.9415\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/replica_classification_models\\excluded_19\\assets\n",
      "Epoch 3/50\n",
      "132/132 [==============================] - 32s 241ms/step - loss: 0.1977 - accuracy: 0.9601 - val_loss: 1.3144 - val_accuracy: 0.5934\n",
      "Epoch 4/50\n",
      "132/132 [==============================] - 32s 245ms/step - loss: 0.6978 - accuracy: 0.5934 - val_loss: 0.6759 - val_accuracy: 0.5934\n",
      "Epoch 5/50\n",
      "132/132 [==============================] - 32s 245ms/step - loss: 0.6751 - accuracy: 0.5934 - val_loss: 0.6727 - val_accuracy: 0.5934\n",
      "Epoch 6/50\n",
      "132/132 [==============================] - 32s 244ms/step - loss: 0.5469 - accuracy: 0.6886 - val_loss: 0.1158 - val_accuracy: 0.9715\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/replica_classification_models\\excluded_19\\assets\n",
      "Epoch 7/50\n",
      "132/132 [==============================] - 32s 241ms/step - loss: 0.0443 - accuracy: 0.9867 - val_loss: 0.0131 - val_accuracy: 0.9973\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/replica_classification_models\\excluded_19\\assets\n",
      "Epoch 8/50\n",
      "132/132 [==============================] - 32s 242ms/step - loss: 0.0036 - accuracy: 0.9998 - val_loss: 0.0149 - val_accuracy: 0.9955\n",
      "Epoch 9/50\n",
      "132/132 [==============================] - 33s 247ms/step - loss: 0.0010 - accuracy: 0.9999 - val_loss: 0.0088 - val_accuracy: 0.9980\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/replica_classification_models\\excluded_19\\assets\n",
      "Epoch 10/50\n",
      "132/132 [==============================] - 31s 238ms/step - loss: 4.4035e-04 - accuracy: 1.0000 - val_loss: 0.0092 - val_accuracy: 0.9973\n",
      "Epoch 11/50\n",
      "132/132 [==============================] - 32s 239ms/step - loss: 2.1626e-04 - accuracy: 1.0000 - val_loss: 0.0093 - val_accuracy: 0.9979\n",
      "Epoch 12/50\n",
      "132/132 [==============================] - 32s 246ms/step - loss: 1.2767e-04 - accuracy: 1.0000 - val_loss: 0.0099 - val_accuracy: 0.9977\n",
      "Epoch 13/50\n",
      "132/132 [==============================] - 33s 247ms/step - loss: 8.4771e-05 - accuracy: 1.0000 - val_loss: 0.0102 - val_accuracy: 0.9979\n",
      "Epoch 14/50\n",
      "132/132 [==============================] - 33s 251ms/step - loss: 6.0164e-05 - accuracy: 1.0000 - val_loss: 0.0107 - val_accuracy: 0.9977\n",
      "Epoch 00014: early stopping\n",
      "6/6 [==============================] - 1s 152ms/step - loss: 2.8095e-06 - accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 17/22 [1:37:28<33:28, 401.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "129/129 [==============================] - 32s 245ms/step - loss: 0.4644 - accuracy: 0.7578 - val_loss: 0.1846 - val_accuracy: 0.9378\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/replica_classification_models\\excluded_20\\assets\n",
      "Epoch 2/50\n",
      "129/129 [==============================] - 32s 250ms/step - loss: 0.1583 - accuracy: 0.9460 - val_loss: 0.1033 - val_accuracy: 0.9400\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/replica_classification_models\\excluded_20\\assets\n",
      "Epoch 3/50\n",
      "129/129 [==============================] - 32s 244ms/step - loss: 0.0175 - accuracy: 0.9924 - val_loss: 0.0060 - val_accuracy: 0.9990\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/replica_classification_models\\excluded_20\\assets\n",
      "Epoch 4/50\n",
      "129/129 [==============================] - 32s 247ms/step - loss: 7.5900e-04 - accuracy: 0.9998 - val_loss: 0.0056 - val_accuracy: 0.9992\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/replica_classification_models\\excluded_20\\assets\n",
      "Epoch 5/50\n",
      "129/129 [==============================] - 31s 236ms/step - loss: 2.7790e-04 - accuracy: 1.0000 - val_loss: 0.0056 - val_accuracy: 0.9992\n",
      "Epoch 6/50\n",
      "129/129 [==============================] - 31s 241ms/step - loss: 2.5322e-04 - accuracy: 1.0000 - val_loss: 0.0057 - val_accuracy: 0.9990\n",
      "Epoch 7/50\n",
      "129/129 [==============================] - 31s 238ms/step - loss: 1.5703e-04 - accuracy: 1.0000 - val_loss: 0.0060 - val_accuracy: 0.9989\n",
      "Epoch 8/50\n",
      "129/129 [==============================] - 31s 240ms/step - loss: 1.4996e-05 - accuracy: 1.0000 - val_loss: 0.0061 - val_accuracy: 0.9989\n",
      "Epoch 9/50\n",
      "129/129 [==============================] - 30s 231ms/step - loss: 4.6096e-06 - accuracy: 1.0000 - val_loss: 0.0065 - val_accuracy: 0.9993\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/replica_classification_models\\excluded_20\\assets\n",
      "Epoch 00009: early stopping\n",
      "8/8 [==============================] - 1s 159ms/step - loss: 0.1268 - accuracy: 0.9515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 18/22 [1:42:21<24:36, 369.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "129/129 [==============================] - 30s 229ms/step - loss: 0.3475 - accuracy: 0.8149 - val_loss: 0.0177 - val_accuracy: 0.9963\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/replica_classification_models\\excluded_21\\assets\n",
      "Epoch 2/50\n",
      "129/129 [==============================] - 31s 242ms/step - loss: 0.0060 - accuracy: 0.9987 - val_loss: 0.0055 - val_accuracy: 0.9989\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/replica_classification_models\\excluded_21\\assets\n",
      "Epoch 3/50\n",
      "129/129 [==============================] - 30s 232ms/step - loss: 8.2569e-04 - accuracy: 0.9998 - val_loss: 0.0054 - val_accuracy: 0.9990\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/replica_classification_models\\excluded_21\\assets\n",
      "Epoch 4/50\n",
      "129/129 [==============================] - 31s 241ms/step - loss: 1.8153e-04 - accuracy: 1.0000 - val_loss: 0.0051 - val_accuracy: 0.9990\n",
      "Epoch 5/50\n",
      "129/129 [==============================] - 31s 243ms/step - loss: 2.9814e-05 - accuracy: 1.0000 - val_loss: 0.0055 - val_accuracy: 0.9990\n",
      "Epoch 6/50\n",
      "129/129 [==============================] - 31s 244ms/step - loss: 1.1849e-05 - accuracy: 1.0000 - val_loss: 0.0060 - val_accuracy: 0.9990\n",
      "Epoch 7/50\n",
      "129/129 [==============================] - 31s 244ms/step - loss: 6.2291e-06 - accuracy: 1.0000 - val_loss: 0.0063 - val_accuracy: 0.9990\n",
      "Epoch 8/50\n",
      "129/129 [==============================] - 32s 247ms/step - loss: 3.8216e-06 - accuracy: 1.0000 - val_loss: 0.0066 - val_accuracy: 0.9990\n",
      "Epoch 9/50\n",
      "129/129 [==============================] - 31s 241ms/step - loss: 2.5844e-06 - accuracy: 1.0000 - val_loss: 0.0068 - val_accuracy: 0.9990\n",
      "Epoch 00009: early stopping\n",
      "9/9 [==============================] - 2s 158ms/step - loss: 10.1475 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▋ | 19/22 [1:47:09<17:13, 344.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "131/131 [==============================] - 32s 243ms/step - loss: 0.4450 - accuracy: 0.7709 - val_loss: 0.1807 - val_accuracy: 0.9402\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/replica_classification_models\\excluded_23\\assets\n",
      "Epoch 2/50\n",
      "131/131 [==============================] - 30s 229ms/step - loss: 0.1306 - accuracy: 0.9532 - val_loss: 0.0283 - val_accuracy: 0.9941\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/replica_classification_models\\excluded_23\\assets\n",
      "Epoch 3/50\n",
      "131/131 [==============================] - 32s 247ms/step - loss: 0.1828 - accuracy: 0.9609 - val_loss: 0.0221 - val_accuracy: 0.9956\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/replica_classification_models\\excluded_23\\assets\n",
      "Epoch 4/50\n",
      "131/131 [==============================] - 30s 231ms/step - loss: 0.0059 - accuracy: 0.9993 - val_loss: 0.0081 - val_accuracy: 0.9978\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/replica_classification_models\\excluded_23\\assets\n",
      "Epoch 5/50\n",
      "131/131 [==============================] - 30s 231ms/step - loss: 0.0021 - accuracy: 0.9996 - val_loss: 0.0072 - val_accuracy: 0.9981\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/replica_classification_models\\excluded_23\\assets\n",
      "Epoch 6/50\n",
      "131/131 [==============================] - 31s 239ms/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.0069 - val_accuracy: 0.9982\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/replica_classification_models\\excluded_23\\assets\n",
      "Epoch 7/50\n",
      "131/131 [==============================] - 32s 241ms/step - loss: 6.2848e-04 - accuracy: 0.9999 - val_loss: 0.0066 - val_accuracy: 0.9983\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/replica_classification_models\\excluded_23\\assets\n",
      "Epoch 8/50\n",
      "131/131 [==============================] - 32s 241ms/step - loss: 2.9170e-04 - accuracy: 1.0000 - val_loss: 0.0066 - val_accuracy: 0.9986\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/replica_classification_models\\excluded_23\\assets\n",
      "Epoch 9/50\n",
      "131/131 [==============================] - 32s 243ms/step - loss: 1.0659e-04 - accuracy: 1.0000 - val_loss: 0.0069 - val_accuracy: 0.9983\n",
      "Epoch 10/50\n",
      "131/131 [==============================] - 33s 250ms/step - loss: 7.0736e-05 - accuracy: 1.0000 - val_loss: 0.0069 - val_accuracy: 0.9986\n",
      "Epoch 11/50\n",
      "131/131 [==============================] - 32s 243ms/step - loss: 4.7179e-05 - accuracy: 1.0000 - val_loss: 0.0073 - val_accuracy: 0.9986\n",
      "Epoch 12/50\n",
      "131/131 [==============================] - 31s 234ms/step - loss: 3.1248e-05 - accuracy: 1.0000 - val_loss: 0.0076 - val_accuracy: 0.9986\n",
      "Epoch 00012: early stopping\n",
      "6/6 [==============================] - 1s 168ms/step - loss: 0.4548 - accuracy: 0.8886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 20/22 [1:53:43<11:58, 359.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "129/129 [==============================] - 31s 242ms/step - loss: 0.4286 - accuracy: 0.7783 - val_loss: 0.1833 - val_accuracy: 0.9383\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/replica_classification_models\\excluded_25\\assets\n",
      "Epoch 2/50\n",
      "129/129 [==============================] - 30s 234ms/step - loss: 0.1628 - accuracy: 0.9458 - val_loss: 0.1409 - val_accuracy: 0.9406\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/replica_classification_models\\excluded_25\\assets\n",
      "Epoch 3/50\n",
      "129/129 [==============================] - 31s 243ms/step - loss: 0.1888 - accuracy: 0.9500 - val_loss: 0.0303 - val_accuracy: 0.9949\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/replica_classification_models\\excluded_25\\assets\n",
      "Epoch 4/50\n",
      "129/129 [==============================] - 32s 243ms/step - loss: 0.0117 - accuracy: 0.9983 - val_loss: 0.0101 - val_accuracy: 0.9984\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/replica_classification_models\\excluded_25\\assets\n",
      "Epoch 5/50\n",
      "129/129 [==============================] - 32s 245ms/step - loss: 0.0031 - accuracy: 0.9997 - val_loss: 0.0067 - val_accuracy: 0.9985\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/replica_classification_models\\excluded_25\\assets\n",
      "Epoch 6/50\n",
      "129/129 [==============================] - 31s 239ms/step - loss: 0.0012 - accuracy: 0.9999 - val_loss: 0.0059 - val_accuracy: 0.9989\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/replica_classification_models\\excluded_25\\assets\n",
      "Epoch 7/50\n",
      "129/129 [==============================] - 32s 245ms/step - loss: 5.0803e-04 - accuracy: 1.0000 - val_loss: 0.0056 - val_accuracy: 0.9989\n",
      "Epoch 8/50\n",
      "129/129 [==============================] - 31s 242ms/step - loss: 3.7144e-04 - accuracy: 1.0000 - val_loss: 0.0059 - val_accuracy: 0.9988\n",
      "Epoch 9/50\n",
      "129/129 [==============================] - 32s 247ms/step - loss: 2.6247e-04 - accuracy: 1.0000 - val_loss: 0.0063 - val_accuracy: 0.9988\n",
      "Epoch 10/50\n",
      "129/129 [==============================] - 31s 240ms/step - loss: 1.0417e-04 - accuracy: 1.0000 - val_loss: 0.0067 - val_accuracy: 0.9989\n",
      "Epoch 11/50\n",
      "129/129 [==============================] - 31s 237ms/step - loss: 1.8168e-05 - accuracy: 1.0000 - val_loss: 0.0071 - val_accuracy: 0.9988\n",
      "Epoch 12/50\n",
      "129/129 [==============================] - 32s 248ms/step - loss: 8.6301e-06 - accuracy: 1.0000 - val_loss: 0.0075 - val_accuracy: 0.9989\n",
      "Epoch 00012: early stopping\n",
      "8/8 [==============================] - 1s 161ms/step - loss: 0.0104 - accuracy: 0.9985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 21/22 [2:00:12<06:08, 368.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "127/127 [==============================] - 32s 246ms/step - loss: 0.4513 - accuracy: 0.7646 - val_loss: 0.1905 - val_accuracy: 0.9317\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/replica_classification_models\\excluded_29\\assets\n",
      "Epoch 2/50\n",
      "127/127 [==============================] - 30s 238ms/step - loss: 0.2164 - accuracy: 0.9215 - val_loss: 0.3488 - val_accuracy: 0.8513\n",
      "Epoch 3/50\n",
      "127/127 [==============================] - 31s 245ms/step - loss: 0.1890 - accuracy: 0.9425 - val_loss: 0.1779 - val_accuracy: 0.9398\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/replica_classification_models\\excluded_29\\assets\n",
      "Epoch 4/50\n",
      "127/127 [==============================] - 31s 245ms/step - loss: 0.1640 - accuracy: 0.9462 - val_loss: 0.1776 - val_accuracy: 0.9398\n",
      "Epoch 5/50\n",
      "127/127 [==============================] - 31s 245ms/step - loss: 0.1637 - accuracy: 0.9463 - val_loss: 0.1767 - val_accuracy: 0.9398\n",
      "Epoch 6/50\n",
      "127/127 [==============================] - 30s 239ms/step - loss: 0.1634 - accuracy: 0.9463 - val_loss: 0.1785 - val_accuracy: 0.9397\n",
      "Epoch 7/50\n",
      "127/127 [==============================] - 31s 244ms/step - loss: 0.1604 - accuracy: 0.9463 - val_loss: 0.1596 - val_accuracy: 0.9392\n",
      "Epoch 8/50\n",
      "127/127 [==============================] - 31s 243ms/step - loss: 0.0439 - accuracy: 0.9815 - val_loss: 0.0065 - val_accuracy: 0.9983\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/replica_classification_models\\excluded_29\\assets\n",
      "Epoch 9/50\n",
      "127/127 [==============================] - 31s 243ms/step - loss: 0.0014 - accuracy: 0.9997 - val_loss: 0.0050 - val_accuracy: 0.9984\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/replica_classification_models\\excluded_29\\assets\n",
      "Epoch 10/50\n",
      "127/127 [==============================] - 30s 238ms/step - loss: 1.5603e-04 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9989\n",
      "INFO:tensorflow:Assets written to: C:/Users/Leor/Desktop/Thesis/replica_classification_models\\excluded_29\\assets\n",
      "Epoch 11/50\n",
      "127/127 [==============================] - 31s 245ms/step - loss: 3.9687e-05 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 0.9989\n",
      "Epoch 12/50\n",
      "127/127 [==============================] - 31s 244ms/step - loss: 2.5226e-05 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9988\n",
      "Epoch 13/50\n",
      "127/127 [==============================] - 30s 236ms/step - loss: 1.8895e-05 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9989\n",
      "Epoch 14/50\n",
      "127/127 [==============================] - 36s 280ms/step - loss: 1.4019e-05 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9989\n",
      "Epoch 15/50\n",
      "127/127 [==============================] - 33s 259ms/step - loss: 1.0596e-05 - accuracy: 1.0000 - val_loss: 0.0047 - val_accuracy: 0.9989\n",
      "Epoch 00015: early stopping\n",
      "11/11 [==============================] - 2s 149ms/step - loss: 0.0036 - accuracy: 0.9992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [2:08:14<00:00, 349.76s/it]\n"
     ]
    }
   ],
   "source": [
    "# Loop over each sample number\n",
    "for exclude_sample in tqdm(np.unique(sample_numbers)):\n",
    "  # Clear graph\n",
    "  K.clear_session()\n",
    "  gc.collect()\n",
    "\n",
    "  # Create filter for training data\n",
    "  train_filter = (sample_numbers != exclude_sample)\n",
    "\n",
    "  # Get indexes of all data\n",
    "  indexes = np.arange(len(sample_numbers))\n",
    "\n",
    "  # Get indexes of training data\n",
    "  train_indexes = indexes[train_filter]\n",
    "\n",
    "  # Get indexes of training and validation data\n",
    "  train_indexes, val_indexes = train_test_split(train_indexes,\n",
    "                                                test_size=0.2,\n",
    "                                                random_state=0,\n",
    "                                                stratify=labels[train_filter])\n",
    "\n",
    "  # Create data generators\n",
    "  training_generator = create_ds(train_indexes, BATCH_SIZE)\n",
    "  validation_generator = create_ds(val_indexes, BATCH_SIZE)\n",
    "  test_generator = create_ds(indexes[~train_filter], BATCH_SIZE)\n",
    "\n",
    "  # Create Callback to save the best model\n",
    "  checkpoint_filepath = os.path.join(MODELS_PATH, f\"excluded_{exclude_sample}/\")\n",
    "  model_checkpoint_callback = callbacks.ModelCheckpoint(\n",
    "      filepath=checkpoint_filepath,\n",
    "      save_weights_only=False,\n",
    "      monitor=\"val_accuracy\",\n",
    "      mode=\"max\",\n",
    "      save_best_only=True)\n",
    "  \n",
    "  # Create Callback for model early stopping\n",
    "  model_es_callback = callbacks.EarlyStopping(\n",
    "      monitor='val_loss', mode='min', verbose=1, patience=5, min_delta=0.0001)\n",
    "\n",
    "  # Create classification model\n",
    "  classification_model = get_model()\n",
    "\n",
    "  # Compile the classification model\n",
    "  optimizer = optimizers.Adam(learning_rate=LEARNING_RATE)\n",
    "  classification_model.compile(\n",
    "      optimizer, loss=losses.BinaryCrossentropy(), metrics=[\"accuracy\"])\n",
    "\n",
    "  # Train the classification model\n",
    "  history = classification_model.fit(\n",
    "      x=training_generator,\n",
    "      validation_data=validation_generator,\n",
    "      epochs=EPHOCS,\n",
    "      callbacks=[model_checkpoint_callback, model_es_callback])\n",
    "\n",
    "  # Load the best saved \n",
    "  classification_model = tf.keras.models.load_model(checkpoint_filepath)\n",
    "\n",
    "  # Evalute the classification model on test set\n",
    "  test_eval = classification_model.evaluate(x=test_generator)\n",
    "\n",
    "  # Clean model for next iteration\n",
    "  classification_model = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8526fece",
   "metadata": {},
   "source": [
    "### ***LOOCV predictions:***\n",
    "\n",
    "Next, let\"s get predictions for each LOOCV for evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eafba22d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [01:14<00:00,  3.40s/it]\n"
     ]
    }
   ],
   "source": [
    "# Define dict for saving predictions and true labels\n",
    "predictions = {}\n",
    "true_labels = {}\n",
    "\n",
    "# Loop over each sample number\n",
    "for exclude_sample in tqdm(np.unique(sample_numbers)):\n",
    "  # Clear graph\n",
    "  K.clear_session()\n",
    "  gc.collect()\n",
    "  \n",
    "  # Create filter for training data\n",
    "  train_filter = (sample_numbers != exclude_sample)\n",
    "\n",
    "  # Get indexes of all data\n",
    "  indexes = np.arange(len(sample_numbers))\n",
    "\n",
    "  # Create test data generator\n",
    "  test_generator = create_ds(indexes[~train_filter], BATCH_SIZE)\n",
    "\n",
    "  # Get saved model path\n",
    "  model_path = os.path.join(MODELS_PATH, f\"excluded_{exclude_sample}/\")\n",
    "\n",
    "  # Load model\n",
    "  classification_model = tf.keras.models.load_model(model_path)\n",
    "\n",
    "  # Get predictions\n",
    "  predictions[exclude_sample] = classification_model.predict(x=test_generator)\n",
    "  \n",
    "  # Get corresponding true labels\n",
    "  true_labels[exclude_sample] = (who_grades[~train_filter] > 2).astype(int)\n",
    "\n",
    "  # Clean model for next iteration\n",
    "  classification_model = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1f24c1",
   "metadata": {},
   "source": [
    "### ***Roc curve:***\n",
    "\n",
    "Next, let\"s plot LOOCV roc curve:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2e714ba7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fpr, tpr, thresholds = metrics.roc_curve(\n",
    "  np.concatenate(list(true_labels.values())),\n",
    "  np.concatenate(list(predictions.values())))\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(fpr, tpr, \"b\", label = f\"AUC = {roc_auc:.3f}\")\n",
    "plt.legend(loc = \"lower right\")\n",
    "plt.plot([0, 1], [0, 1],\"r--\")\n",
    "plt.xlim([-0.05, 1.05])\n",
    "plt.ylim([-0.05, 1.05])\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.title(\"Receiver Operating Characteristic\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7b822b",
   "metadata": {},
   "source": [
    "### ***MSI parsers closing:***\n",
    "\n",
    "Next, let\"s close MSI parsers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5c5bdfc8-4b31-4968-ae11-f271467cbec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Closing parsers\n",
    "for reader in parsers.values():\n",
    "  if reader.m:\n",
    "    reader.m.close()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5c73559c04fc51cf6f25e380b3ded5183311c605494f1c18f4c2cfbf285cb958"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('tf_gpu_jup')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
